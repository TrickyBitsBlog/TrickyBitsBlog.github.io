<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://trickybitsblog.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://trickybitsblog.github.io/" rel="alternate" type="text/html" /><updated>2025-02-11T15:04:09-07:00</updated><id>https://trickybitsblog.github.io/feed.xml</id><title type="html">Tricky Bits</title><subtitle>Nowadays when you are learning software, so much of it takes place in a carefully crafted and abstract world,  far away from the hardware and even the operating system. Programming languages today don&apos;t help because they  have runtimes on top of runtimes. TrickyBits is going to strip away these layers and look at the world beneath to get a better understanding of what is really happening. x86, ARM, Apple Silicon, and GPUs are all fair game.</subtitle><entry><title type="html">Nanite Deep Dive - Part 1</title><link href="https://trickybitsblog.github.io/2024/04/20/nanite.html" rel="alternate" type="text/html" title="Nanite Deep Dive - Part 1" /><published>2024-04-20T00:00:00-06:00</published><updated>2024-04-20T00:00:00-06:00</updated><id>https://trickybitsblog.github.io/2024/04/20/nanite</id><content type="html" xml:base="https://trickybitsblog.github.io/2024/04/20/nanite.html"><![CDATA[<p>Nanite was a new addition to UnrealEngine 5.0 and it rightfully got a lot of attention, but what is it?? Epic call it a  “virtualized geometry system” but it the “virtualization” part is only a tiny part of it, the “geometry” part is the impressive bit.</p>

<p>Nanite is a system for rendering seemingly unlimited amounts of ultra-high resolution geometry at real-time frame rates. Total triangles in scene can be in the billions, with millions of instances, the resulting visible triangles can be pixel sized.  The individual rendering components to Nanite is built around have existed for a number of years, and have been used in other game engines.  However, Epic have done a phenomenal job of bringing all the pieces together and seamlessly integrating it in to the Unreal Engine - it mostly just works.</p>

<p>In part one of this series let’s take a deep dive and see exactly how Nanite works, in part two we’ll take a look at how Nanite generates shadows and finally in part 3 we’ll deep dive in to Lumen and see how it works with both Nanite and traditional geometry.</p>

<p>This is going to be a long one…..</p>

<hr />

<p>Nanite is an entirely GPU driven, asynchronous, renderer. This means everything from culling and occlusion, LOD selection, to the actual rendering of triangles in the correct materials are all handled by various types of GPU shaders. The CPU isn’t involved in the process at all, other than starting it by submitting a template of draw calls and dispatches, simply because the GPU can’t dispatch itself, at the end it gathers feedback from a buffer the GPU filled. This does mean the GPU has to do some work that the CPU would typically do, such has building data structures for a later pass. While such operations are more efficient for the CPU, getting the required data would mean synchronizing the CPU and GPU, keeping such operations on the GPU is essential even if it means dispatching a 1x1 thread group.  The CPU does play a big role in parsing the feedback buffers which includes stats, visibility data and virtual memory info which controls streaming.</p>

<p>GPU driven rendering by itself is nothing new, indirect rendering allows limited control of rendering from the GPU, and its been around since DX11. Unreal already uses it in the traditional rendering path but Nanite takes asynchronous rendering to a while new level.</p>

<p>At the highest level Nanite does the following operations:</p>

<p>1) High level instance occlusion and culling</p>

<p>2) Render Visibility Buffer for only Nantie geometry</p>

<p>3) Process the visibility buffer along with the traditional depth buffer to get final visibility</p>

<p>4) Resolve the visibility buffer with materials in to a traditional G-Buffer</p>

<p>5) Feedback data to the CPU for streaming and stats</p>

<p>The entire Unreal engine is very good at putting markers in to the GPU profile and Nanite is no different. Using a tool like RenderDoc you can see the individual operations and they follow the above flow.</p>

<p>1) Cull all the clusters and generate the visibility Buffer</p>

<p><img src="/assets/img/posts/nanite/Untitled%206.png" alt="Untitled" /></p>

<p>2) Post Process visibility buffer so nanite and traditional geometry play nice together</p>

<p><img src="/assets/img/posts/nanite/Untitled%207.png" alt="Untitled" /></p>

<p>3) Apply final materials to generate traditional G-Buffer</p>

<p><img src="/assets/img/posts/nanite/Untitled%208.png" alt="Untitled" /></p>

<hr />

<p>Before we dive in to the above operations in more detail, there are a few pieces of rendering tech we need to understand.</p>

<h2 id="visibility-buffer">Visibility buffer</h2>

<p>Like most modern game engines Unreal 5 uses a pretty traditional deferred rendering system. The goal of any deferred rendering system is to avoid performing complex lighting and shadows for pixels that are not visible, with deferred rendering the complexity of the lighting and shadows is independent of the materials. Deferred rendering does this by rendering depth-buffered surface attributes to multiple frame-buffers instead of depth-buffered complete pixels. This collection of surface attribute frame-buffers are collectively what we call the G-Buffer.  How expensive the G-Buffer is depends on how many attributes are stored, typically its things like depth, albedo, normal, detail, gloss, velocity etc.</p>

<blockquote>
  <p>Deferred rendering relies on the depth buffer being correct and is not used for alpha rendering. Unreal in no different and the alpha materials in unreal are rendered in a traditional forward pass later in the frame. The fact that Nanite cannot render alpha materials is related to this.</p>
</blockquote>

<p>In Unreal, for traditional materials it’s while rendering the G-Buffer that the user defined material graphs are applied. Shaders are being switched on the pixel side for different materials, on the vertex side shaders are being switched based on asset type, World Position Offset and UV sets. Unreal does the typical early depth pass to make building the G-Buffer more efficient, the early depth buffer is also important for Nanite.</p>

<p>After the G-Buffer is rendered shadows and lighting are done in screen space independently of the source materials. Unreal uses at least 5 RGBA 16bit frame buffers and as the resolution increases these buffers can consume hundreds of megabytes of memory (even worse in the editor) and the bandwidth utilized by these buffers gets unmanageable as multiple full screen passes are performed throughout the frame.</p>

<p>Nanite geometry does ultimately end up in the same G-Buffer as the traditional geometry but it doesn’t directly render the G-buffer, Nanite renders what is called a visibility buffer and practically speaking a visibility buffer is the minimal amount of data you can render for a pixel and still resolve the material at a later stage - typically depth and some sort of polygon id.  The Gbuffer made lighting and shadows independent of the scene complexity, the visibility buffer decouples materials from the scene complexity, things like overdraw and occlusion only affect the visibility buffer while the expensive material processing is applied later only to pixels that are known to be visible. You can find more info about visibility buffer <a href="https://www.gdcvault.com/play/1023792/4K-Rendering-Breakthrough-The-Filtered">here</a>.</p>

<p>The pixel data in a visibility buffer is independent of the final material and therefore pixel shaders don’t have to change for the entire visibility pass. Nanite only supports one type of geometry so therefore the vertex shaders don’t have to change either. In theory Nanite can render the whole scene with a single API call.  In practice, things like World Position Offset (WPO) puts a wrench in this single API call theory, because it requires new vertex and compute shaders to handle the user specified WPO calculation and is one of the reasons WPO is slower to render within Nanite that non WPO geometry - use it carefully.</p>

<blockquote>
  <p>The visibility buffer is the only time geometry is rendered in a traditional sense. All rendering after the visibility buffer is performed in screen space. Due to the smaller render target memory footprint, the visibility buffer offers memory bandwidth benefits compared to a G-Buffer for a similar sized frame buffer.</p>
</blockquote>

<p>For Nanite the visibility buffer is a 64bit unordered buffer, 32bits are used by depth and 32bits are used to identify the triangle in a mesh (these 32bits contain a draw ID and a polygon ID). There is no material specific data stored in the visibility buffer, this is all derived later from the triangle information.</p>

<blockquote>
  <p>In a RenderDoc capture the visibility buffer is called Nanite.VisBuffer64, in C++ code it is created in NaniteCullRaster.cpp in function InitRasterContext() and is called RasterContext.VisBuffer64.</p>
</blockquote>

<p>The Nanite visibility buffer, being an ordered buffer, can be arbitrarily written to by either a compute shader or the traditional pixel shader. In fact nanite uses both based on the size of the triangles.  When utilizing the the pixel shader pipeline, for large triangles, only the visibility buffer is bound, no traditional depth buffers or frame buffers are configured and the pixel shader does atomic unordered writes to the visibility buffer in exactly the same way as the compute shader (which is used for small triangles).</p>

<p>Both the pixel shader and the compute shader do their own depth compares on the custom depth data in the visibility buffer, the depth buffer hardware is not used. The software compute based rasterizer and the hardware pixel based rasterizer can in theory operate at the same time utilizing async compute. Access to VisBuffer64 has to be atomic because all the triangles within a cluster are rendered at once across multi compute threads (and if using async compute then also pixel shader threads) and they could all touch the same pixel at the same time. The visibility buffer needs to contain predictable data that is consistent across all compute threads. The depth component of the visibility buffer will ultimately and predictably resolve the final visibility.</p>

<blockquote>
  <p>The Nanite depth data within VisBuffer64 is effectively a traditional per pixel depth buffer but it only contains Nanite geometry. This buffer is not a hardware depth buffer and can’t be directly used by the depth buffer hardware.</p>
</blockquote>

<p>The result of the visibility pass is the same no matter if it was generated by the compute pipe or the pixel pipe, at the end of the pass you cannot determine which pixels were rendered with which pipe. Each render pipe is used for its optimal purpose - The pixel shader pipeline is used for larger triangles and it takes advantage of the hardware setup and rasterization along with the typical efficiencies the pixel pipe. However when you get to small triangles pixel shaders can become very inefficient due to quad coverage, so Nanite utilizes a software rasterizer within a compute shader. This compute shader is a monolithic shader that includes all the vertex fetch, vertex transformation and rasterizing - this compute shader gets recompiled for every material that utilizes WPO.</p>

<p>One the visibility buffer is rendered it is resolved to normal g-buffer with the following high level steps, once resolved to a G-Buffer deferred lighting and shadows can be applied as normal.</p>

<p>For each pixel on the screen we do the following operations, depth was resolved while rendering so only visible pixels remain:</p>

<ul>
  <li>
    <p>Get drawID/triangleID at screen-space pixel position.</p>
  </li>
  <li>
    <p>Load data for the 3 vertices from the index buffer and then load the vertex data from vertex buffer.</p>
  </li>
  <li>
    <p>Project the vertices in to screen space compute the partial derivatives from barycentric coordinates to get the triangle gradients</p>
  </li>
  <li>
    <p>Interpolate vertex attributes at pixel position using the triangle gradients, perspective correction is computed with position W.</p>
  </li>
</ul>

<p>All of the above seems like a lot of work but it has quite efficient caching and data reuse and it doesn’t take too long to execute as its only done for visible pixels.</p>

<p>Once the above steps are done the shader has the same information as a normal pixel shader and can compute outputs in a normal manner. - Unreal utilizes this to build the material graph as a shader function and use the core function from a pixel shader using hardware interpolated attributes or in a resolve shader using computed attributes and get the same results.</p>

<blockquote>
  <p>When resolving the visibility buffer there are sometimes artifacts related to DDX and DDY which don’t exist in the resolve shader. This can also cause artifacts when selecting mip levels. The artifacts are usually not too visible.</p>
</blockquote>

<h2 id="nanite-mesh-data---nodes-and-clusters">Nanite mesh data - Nodes and Clusters</h2>

<p>The build process of a Nanite mesh is quite complicated. A mesh is built from nodes and clusters, a cluster is the only renderable part and always has 128 triangles. The 128 triangles in a cluster represent some LOD and that cluster will typically have child clusters presenting higher LODs. Once the renderer gets to the LOD level it wants, it stop looking at the children (the LOD system also plays a big role in virtualization). Nodes form a BVH within the mesh and connect all the clusters together, the nodes are a critical component of the culling stage. The build process is very careful in how it allocates clusters so there are no seams between LODs and edges that can’t easily be LODed.</p>

<p>The output data is heavily compressed and looks nothing like traditional GPU geometry with index and vertex buffers. The resulting data is bound to the GPU as a block of data and is entirely decoded by the shader.</p>

<p>The entire build process is a complicated and quite slow process and is not practical at runtime, and is the primary reason why you cannot animate or deform Nanite meshes on the fly. Nanite meshes can be instanced and instancing is very efficient. Each instance gets its own transform in to the world, and these transforms can be animated, therefore Nanite geometry can move, it just can’t internally deform (WPO is a minor exception).</p>

<h2 id="software-rendering">Software rendering</h2>

<p>In 1999 nVidia released the GeForce256, this was the first consumer GPU that did transform and lighting, and implemented the traditional GL style graphics pipeline entirely in hardware. Since then software rendering hasn’t been a thing, so why is Nanite going back to software? You might be asking if a software renderer in a compute shader can be faster than a dedicated hardware renderer - the answer is yes, way faster, maybe 3x or 4x faster for small triangles. Small triangles is where Nanite excels but not all of Nanite is software rendered, only small triangles, big triangles use the traditional hardware rasterizer.</p>

<p>The reason a software rasterizer in a compute shader is faster is because a pixel shader always computes a 2x2 quad of pixels, even if only 1 pixel is used, for small triangles the pixel shader might only be 25% efficient. If you render big triangles the hardware rasterizer is quite efficient, except at the edges of a triangle, all 4 pixels in the 2x2 quad contribute to the output.  The actual hardware performance might vary a little due to the hardware coalescing but in general the hardware is quite terrible at combining small triangles into quads.</p>

<p>The Nanite software rasterizer is optimized for small triangles. A single compute thread renders a single triangle, a thread-group of 128 compute threads, renders the 128 triangles of a single cluster at the same time.</p>

<p>Nanite will decide cluster by cluster whether to render in software or hardware, a single cluster can only be one of the other. It decides on the fly based on the projected area of the cluster which allows clusters to be rendered where they are most efficient.</p>

<p>A compute thread-group runs in lockstep so one authoring optimization for Nantie is to keep the source triangles roughly the same size, the compute software renderer cannot handle big triangles. For ultra high resolution source meshes the LOD system will mostly handle it. If the source mesh isn’t high resolution then triangles can wildly vary in size and a cluster containing a single big triangle will be forced down the hardware path where it might not be efficient - tessellating that large triangle would make the whole cluster more efficient.</p>

<p>Its important to know that the hardware pixel shader renderer doesn’t use traditional render targets and depth buffers, if fact they aren’t even bound. The pixel shader only binds the visibility buffer as a UAV buffer and it performs the exact same write operations as the computer shader. After a pixel is rendered it is impossible to know whether it was hardware or software - for debugging you can force everything to the hardware path.</p>

<h2 id="hzb-and-reusing-depth">HZB and reusing depth</h2>

<p>Within a single frame Unreal does two full Nanite render passes, called the <code class="language-plaintext highlighter-rouge">main pass</code> and the <code class="language-plaintext highlighter-rouge">post pass</code>, it might seem inefficient to do it twice but its for a very good reason. The only real difference between the two passes is what HZB is used for culling.</p>

<p>A Hierarchical Z Buffer or HZB is effectively a set of mip maps for the depth buffer and are generated from the main depth buffer in a pixel or compute shader. Rather than averaging the source pixels like a color buffer mip map, a Z buffer mip map uses min/max.</p>

<p>The problem for Nanite is when it does the main pass there isn’t a complete depth buffer or HZB. To account for this the main pass renders using a reprojection last frames HZB which is complete - it contains all tradition and Nanite geometry.  Nanite will project the current geometry into last frames depth buffer by simply using last frames transforms, this is far more reliable that projecting the last frames depth buffer into the current frames view as reprojecting a buffer requires holes to be filled and boundary cases to be handled. This is really clever as it allow Nanite to cull against other Nanite which wouldn’t be possible if the current incomplete depth buffer was used.</p>

<p>The main pass has to be conservative and not over cull, and not all clusters can be handled this way by the main pass. There will be clusters can’t be reprojected in to last frames depth buffer. Therefore a post pass is performed which is identical to the main pass, other than a new HZB is built from the current frame’s depth data, this new HZB includes all the already rendered Nanite and traditional geometry.</p>

<p>Two passes are only performed if needed, if there are no indeterminate clusters after the first pass then the second pass isn’t needed and no time is wasted generating the current HZB. However, in most real-world scenarios there tends to always be two passes.</p>

<p>All HZB buffers within Unreal are FP16 single channel textures, they look like this:</p>

<p><img src="/assets/img/posts/nanite/Untitled%2017.png" alt="Untitled" /></p>

<p>size = 1024x512</p>

<p><img src="/assets/img/posts/nanite/Untitled%2018.png" alt="Untitled" /></p>

<p>size = 128x64</p>

<p><img src="/assets/img/posts/nanite/Untitled%2019.png" alt="Untitled" /></p>

<p>size = 32x16</p>

<blockquote>
  <p>As you can imagine it’s very efficient to use these small levels to conservatively occlude simple bounding volumes. To ensure we the culling remains conservative it is important to select the correct min/max function when generating the HZB. If smaller depth values are closer to the camera then the HZB mip level is the max of the inputs - this represents a distance which is the furthest back of all the source pixels, if you are behind this you are guaranteed to be occluded even in the higher resolution buffers.</p>
</blockquote>

<h2 id="gpu-virtual-memory">GPU Virtual Memory</h2>

<p>The feedback also includes virtualization results, this consists of what GPU buffer pages were accessed but not were not present - when this occurs a request is made for the memory and in the mean time a lower resident LODs is used, the lowest LODs are always present in the GPU memory. The CPU will demand load the required pages and map them to the GPU so they can be used in a future frame, the CPU will remove GPU pages if it starts getting low on physical memory. This is the virtualization part which allows Nanite to have billions of triangles, it works just like virtual memory on a CPU.</p>

<hr />

<h1 id="lets-render-a-frame">Let’s Render a frame</h1>

<p>In this example frame we are going to use a very simple scene. The rectangle is traditional geometry and renders via the traditional deferred path and the spheres are Nanite geometry. Step by step we are going to go through a frame to see what Nanite renders and how it ultimately ends up in the standard G-Buffer. We aren’t going to deal with Shadows and lighting, we’ll do that is part two.</p>

<h3 id="stage-1-depthpass">Stage 1 DepthPass</h3>

<p>The first stage of rendering is to render the depth of all opaque traditional geometry, this is typically the first pass without Nanite but this is enforced if Nanite is enabled. The main depth buffer in Unreal is called SceneDepthZ and ultimately is the depth buffer used for deferred rendering and all Nanite geometry will ultimately end up in this depth buffer.</p>

<p><img src="/assets/img/posts/nanite/Untitled%209.png" alt="Untitled" /></p>

<p>Within RenderDoc you can see this is the normal early depth pass</p>

<p><img src="/assets/img/posts/nanite/Untitled%2010.png" alt="Untitled" /></p>

<p>In this simple test scene the only traditional geometry is the rectangle.</p>

<h3 id="stage-2-initcontext">Stage 2 InitContext</h3>

<p><img src="/assets/img/posts/nanite/Screenshot_2023-08-22_152636.png" alt="Untitled" /></p>

<p>This one is pretty simple; it’s a compute shader that clears the visibility buffer (VisBuffer64) to default empty values.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2011.png" alt="Untitled" /></p>

<blockquote>
  <p>Within in editor the allocated size of buffers is bigger than the render size, only the pixels needed for the current window size are rendered. This does not happen in fullscreen builds.</p>
</blockquote>

<p>Nanite supports async compute, when enabled this compute based clear of the visibility buffer can overlap with rasterizing of the depth buffer in the previous stage, assuming there are available shader cores.</p>

<h3 id="stage-3-visbuffer">Stage 3 VisBuffer</h3>

<p>This is the main render pass for the visibility buffer, everything do to with Nanite rendering is here.</p>

<p>The first thing it does is initialize various queues, remember everything is compute so none of the init can be done on the CPU. InitArgs is a single dispatch of a compute shader that resets all the working buffers that will track clusters across both hardware and software and across main and post passes.</p>

<p>From this point on rendering of the visibility buffer can take one of two forms - it either does one pass of the geometry, or it does two.</p>

<p>This is what two passes looks like, there is a main pass, a HZB build and a post pass. Most frames in a complex scene will do two passes.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2012.png" alt="Untitled" /></p>

<p>When there there is no post pass and Nanite can render everything in  a single pass, that single pass is called NoOcclusionPass, it is not called main pass. In RenderDoc it looks slightly different but is equivalent to main pass.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2013.png" alt="Untitled" /></p>

<p>Any nanite pass (main, NoOcclusion or post) breaks down into the following sequence of operations. Although the sequence and theory of the operations is the same in each pass the actual shaders are different due to where it gets data from and what sort of feedback is generated.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2014.png" alt="Untitled" /></p>

<p><strong><em><code class="language-plaintext highlighter-rouge">Instance Cull - NaniteInstanceCull.usf</code></em></strong></p>

<p>This culls whole instances which will be further culled in to clusters in the next step. This step performs frustum culling, distance culling, global plane culling and pixel HZB culling. These individual culling options can be turned on or off with <code class="language-plaintext highlighter-rouge">r.Nanite.Culling.Drawdistance</code>, <code class="language-plaintext highlighter-rouge">r.Nanite.Culling.Frustum</code>, <code class="language-plaintext highlighter-rouge">r.Nanite.Culling.GlobalClipPlane</code>, <code class="language-plaintext highlighter-rouge">r.Nanite.Culling.HZB</code>, <code class="language-plaintext highlighter-rouge">r.Nanite.Culling.WPODisableDistance</code>.</p>

<p>All nanite data is accessible to the GPU at all times. The static input data to the cull stage is the GPU Scene containing the primitives and the instance data, along with the previous frame HZB texture. Nanite views is an input array of all the views that need to be processed (camera, shadows etc), all active views are processed in a single pass and multiple outputs are produced - we pretty much ignore this for this breakdown.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2015.png" alt="Untitled" /></p>

<p>The output data is all read/write UAV buffers:</p>

<p><img src="/assets/img/posts/nanite/Untitled%2016.png" alt="Untitled" /></p>

<p>Distance culling will cull objects that are too far from the camera and it will also disable WPO in the distance for performance reasons. This WPO disable distance is set by the asset builder on a per instance basis.</p>

<p>HZB culling uses a screen space rect of the instance bounding volume to determine if the whole instance is occluded or not. It tests against the mip map where the screen rect is &lt; 4x4 pixels. The work is done in a shader function called IsVisibleHZB() and GetMinDepthFromHZB(). For the main pass the HZB is the complete previous frame, for the post pass its the HZB that was just generated.</p>

<p>If the instance isn’t visible no further processing is done for the instance, if it is visible (or being forced to render due to various debug flags), then the node is added to the output via function StoreCandidateNode(). The output data actually consists of 2 buffers, one is a byte buffer which contains the actual cluster data (OutMainAndPostNodesAndClusterBatches), the other is OutQueue that contains the atomic state of the output buffer (FQueueState).  The node data is 8 bytes per visible instance in the main pass or 12 bytes in the post pass. The first 32bit field is packed with the instance id and node flags, the second 32bit field is view id and the node index. The extra 4 bytes in the post pass data is used to store an enabled bit mask.</p>

<p>InstanceCull also keeps track instances that might be visible but were occluded by the HZB in RWBuffer OutOccludedInstances, the data recorded is the viewid and instanceid.</p>

<p><strong><em><code class="language-plaintext highlighter-rouge">PersistentCull - NaniteClusterCulling.usf</code></em></strong></p>

<p>Most of the culling magic is here…. At a high level this stages processes all the visible instances from the previous stage and generates two lists of clusters that need to be rendered, one for the hardware renderer and one for the software renderer.</p>

<p>The node and cluster culling is the key to Nanite and is where the automatic LOD comes from and is where the concept of virtual geometry comes from. The previous stage culled only instances which are always in memory, this stage culls down to the individual clusters within an instance. The low resolution parent nodes and clusters are always in memory so there is always something that can be rendered. The higher resolution children nodes and clusters may not be in memory. The loading of these higher resolution children is done by the CPU using feedback data from this pass.</p>

<p>All the Nanite cluster data is in a huge virtual byte buffer called Nanite.StreamingManager.ClusterPageData while the BVH hierarchy is in a buffer called Nanite.StreamingManager.Hierarchy. These are both dynamically streamed.</p>

<p>The culling operations that are performed on nodes and clusters are the same as the culling of instances. Backwards facing culling is not performed as most clusters that are facing away from the camera are occlusion culled by the other side of the object. If a parent node is culled and isn’t visible then its children aren’t visible and the processing of that node stops. If a parent node has a small enough triangle size then processing of children stops - this is where the dynamic and automatic LOD comes from. Finally if the memory for a child node isn’t present processing will stop at the parent node and a request will be made for the child - visibly you’ll see a lowe resolution LOD until the higher resolution data is loaded.</p>

<p>A function called PersistentNodeAndClusterCull() in NaniteHierarchyTraversal.ush is responsible for the recursive culling and traversal of the per-mesh node and cluster BVHs. Tree-culling in a compute shader is awkward as the number of nodes that need to be processed is dynamic and can be anywhere from zero to hundreds of thousands, the CPU would need to know up front what to dispatch. Mapping compute threads 1:1 to trees can result in extremely long serial processing that severely under utilizes the GPU and takes too long. Conversely, mapping threads 1:1 to leaf nodes can end up leaving most threads idle.</p>

<p>For optimal GPU processing the CPU spawns just enough worker threads to fill the GPU and uses a Multiple Producer, Multiple Consumer job queue to keep the threads busy.  A worker thread atomically consumes the next item in the queue and keeps going until there is nothing left. The work queue can contain nodes or cluster and initially the queue is populated with only nodes generated by preceding instance cull pass Workers threads will continuously consume items from the queue and sometimes produce new items which are atomically added to the end. When nodes are processed they will append work items to the queue for each of the visible children, this work will be in the form of a new node, or if at a leaf a cluster of triangles. Once the queue is empty all the work is done.  The two core functions that do the work are ProcessNodeBatch and ProcessClusterBatch. Only nodes generate new work, clusters are only consumed and never generate new work.</p>

<p>Once the culling process stops the initial set of instances that might represent billions of triangles have been hierarchically reduced to just what is visible, and those visible clusters have a fairly consistent number of triangles per frame because LOD for a given cluster automatically happens based on screen error.  .</p>

<blockquote>
  <p>This stage can appear as <code class="language-plaintext highlighter-rouge">NodeAndClusterCull</code> in a capture, the difference is <code class="language-plaintext highlighter-rouge">PersistentCull</code> is a single kernel that operates on an atomic list of nodes and clusters, whereas <code class="language-plaintext highlighter-rouge">NodeAndClusterCull</code> is multiple compute kernels that operate either on nodes or clusters. <code class="language-plaintext highlighter-rouge">PersistentCull</code> is the current default as it is more efficient. <code class="language-plaintext highlighter-rouge">GNanitePersistentThreadCulling</code> is used to select between them in code and this is controlled by <code class="language-plaintext highlighter-rouge">r.Nanite.PersistentThreadCulling</code></p>
</blockquote>

<p><strong><em><code class="language-plaintext highlighter-rouge">CalculateSafeRasterizerArgs</code></em></strong>, <strong><em><code class="language-plaintext highlighter-rouge">RasterBinClassify</code></em></strong>, <strong><em><code class="language-plaintext highlighter-rouge">RasterBinReserve</code></em></strong>, <strong><em><code class="language-plaintext highlighter-rouge">RasterBinScatter</code></em></strong></p>

<p>These next 4 compute stages are grouped together, all of them are in NaniteRasterBinning.usf.</p>

<p>These stages ultimately generate the execute indirect buffers and the draw indirect buffers for the following software and hardware render stages.  Remember there is no CPU involvement so even the most simple tasks are done as multiple passes in compute.</p>

<p><strong><em><code class="language-plaintext highlighter-rouge">HW Rasterize</code></em></strong>, <strong><em><code class="language-plaintext highlighter-rouge">SW Rasterize</code></em></strong></p>

<p>HW Rasterize uses a traditional pixel shader to render large triangle clusters to the visibility buffer, while SW Rasterize uses a compute shader to render small triangle clusters to the same visibility buffer. The reason it is possible to mix hardware and software rendering without issues such as depth fighting or cracks along edges of triangles, is because DX12 has super strict and very well-defined rasterization rules. The software rasterizer can replicate these rules and seamlessly interact with the hardware renderer so triangles can touch or intersect without any cracks or discontinuities.</p>

<p>As previously stated HW rasterize is better suited to large triangles, SW for very small triangles. The split between HW and SW is performed by PersisentCull based on the projected screen area of the cluster - it doesn’t know anything about the size of the triangles within the cluster so artists should keep them consistent when building meshes.</p>

<p>The visibility buffer has fixed data for the hardware and software renders, and this data is independent of the materials, therefore shaders don’t have to changes and everything can be rendered by a single draw and/or compute call.  World position offset on a material does change the vertex processing which does require shader changes, for the compute path this is an entirely new monolithic shader. Every WPO material will require its own shaders and its own set of draw calls.</p>

<p>Async compute can allow the software rasterizer to run at the same time as the hardware rasterizer. It is controlled in code by <code class="language-plaintext highlighter-rouge">r.Nanite.AsyncRasterization</code> but the GPU also has to support async compute (<code class="language-plaintext highlighter-rouge">GSupportsEfficientAsyncCompute</code> is true).  On DX12 nvidia hardware does not support compatible async compute but AMD does. Xbox and PS5 always sets <code class="language-plaintext highlighter-rouge">GSupportsEfficientAsyncCompute</code> and is a good reason to test on AMD hardware and Xbox/PS5.</p>

<p>For performance comparison, all clusters can be forced to the hardware rasterizer by setting <code class="language-plaintext highlighter-rouge">r.Nanite.ComputeRasterization 0</code>. You can’t force everything to render with software.</p>

<p>For our simple test scene this is the resulting visibility buffer, in this case rendered entirely by the software rasterizer in a single pass.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2020.png" alt="Untitled" />
The visibility buffer contains just Nanite geometry, there is no interaction at this point with Nanite and traditional geometry.</p>

<p><strong><em><code class="language-plaintext highlighter-rouge">BuildPreviousOccluderHZB</code></em></strong></p>

<p>This stage is only present if there is a post pass and takes in SceneDepthZ (the traditional depth buffer) along with the current and up to date Nanite visibility buffer and it generates a new HZB that will be used by the post pass. It does this by using 3 consecutive compute shaders:</p>

<p><img src="/assets/img/posts/nanite/Untitled%2022.png" alt="Untitled" /></p>

<p>The first pass takes the current Nanite visibility buffer, which also contains Nanite depth, and the traditional depth buffer, combines the depths and generates the first three mips of the new HZB. The polygon data in the visibility buffer isn’t needed at this stage.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2023.png" alt="Untitled" /></p>

<p>The tranditional depth buffer contents</p>

<p><img src="/assets/img/posts/nanite/Untitled%2024.png" alt="Untitled" /></p>

<p>The visibility buffer contents including 32bits of depth</p>

<p><img src="/assets/img/posts/nanite/Untitled%2025.png" alt="Untitled" /></p>

<p>The output includes all Nanite and traditional geometry. This is the highest resolution buffer in the stack, final two compute shaders take this and generate lower mips.</p>

<h3 id="stage4-emitdepthtargets">Stage4 EmitDepthTargets</h3>

<p>At this stage the main and post pass are done and rendering of the visibility buffer is complete. This is where the visibility buffer starts to be resolved in to the standard G Buffer. Everything from here is a screen space operation.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2026.png" alt="Untitled" /></p>

<p><strong><em><code class="language-plaintext highlighter-rouge">ClearRenderTarget</code></em></strong></p>

<p>This one is pretty self explanatory. Nanite.MaterialResolve is a 2 channel frame buffer that holds the global material ID and various flags for each visible Nanite pixel, before running the material resolve the material id buffer is cleared to black. Within this 2 channel 32bit integer frame buffer, R contains material info flags like receives decals, has distance fields, shading bin and lighting channels - basically things needed later. G is the material id, in our example the material id is zero as there is only one material.</p>

<p>The function PackMaterialResolve() packs all the required data into the pair of 32bit values.</p>

<p><strong><em><code class="language-plaintext highlighter-rouge">Emit Scene Depth/Resolve/Velocity (NaniteExportGBuffer.usf)</code></em></strong></p>

<p>The material resolve computes the triangle and material information from the Nanite visibility buffer. The material id is only written if the Nanite depth is in front of the scene depth and the scene depth is updated. This is where Nanite depth gets combined with the main depth buffer, Nanite pixels that are in front will use depth write in the pixel shader to update SceneDepthZ. The result is a complete depth buffer and a material id buffer containing only the visible Nanite pixels, Nanite pixels behind traditional geometry have now been culled on a per pixel level, any Nanite clusters that incorrectly passed through HZB culling are now correctly resolved.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2027.png" alt="Untitled" /></p>

<p>Nanite.MaterialResolve contains flags in the red channel and the material ID in the green channel. This shader also processes the depth buffer, for the first time we have just the visible Nanite pixels with respect to the traditional depth buffer. These are the only pixels that will be processed going forwards.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2028.png" alt="Untitled" /></p>

<p>SceneDepthZ is now complete and can be used for traditional deferred shading and computing world space positions without regard for which pixels are Nanite.</p>

<p>The same shader writes pixel velocity but only for transform based movement - either the object moving or the camera moving, pixel velocity from WPO movement is evaluated later (another reason why WPO on nanite is slower)</p>

<p><strong><em><code class="language-plaintext highlighter-rouge">Emit Scene Stencil</code></em></strong></p>

<p>This is only present if the pixel shader hardware cannot write stencil reference values from the shader. If the hardware can write stencil values then this pass is combined with the prior.</p>

<p>The stencil is written based on flags in the material, it is used for things like decal materials.</p>

<p><strong><em><code class="language-plaintext highlighter-rouge">Emit Material Depth</code></em></strong></p>

<p>This stage converts the material ID to a hardware depth buffer. This sounds weird but its one of the very clever features of Nanite. Later on we are going to have to identify materials based on the material ID value, the GPU already has hardware to efficiently mass reject or accept pixels based on a value - its called the depth compare. If the material ID is in a pixel buffer then every material shader will have to do a texture read and compare at the top of the shader and terminate if the material is the wrong ID, If a depth buffer is prepared where each material has a different depth value, the depth compare hardware can be used to cull/accept pixels before the pixel shader even runs!! This is genius.</p>

<p>The input is Nanite.MaterialResolve and the output looks like this:</p>

<p><img src="/assets/img/posts/nanite/Untitled%2029.png" alt="Untitled" /></p>

<p>Our simple test scene only has a single Nanite material so for this example all the white pixels are the same value (real depth=0.00006)</p>

<h3 id="stage5-basepass">Stage5 BasePass</h3>

<p>Before the Nanite base pass is performed the base pass is performed on traditional geometry</p>

<p><img src="/assets/img/posts/nanite/Untitled%2031.png" alt="Untitled" /></p>

<p>The traditional geometry pixels are now in the G-Buffer via the completely normal render path. The only interaction with Nanite at this point is that traditional pixels aren’t processed where Nanite pixels will ultimately be.</p>

<p>Nanite materials are added on top of this with a full screen pass per material using the nanite material depth buffer.</p>

<p>This can become a performance problem as every Nanite material has to do a full screen pass, this operation can get very expensive at high resolutions. Remember everything is running on GPU so there a few compute shaders that execute prior to this to generate indirect draw buffers, these compute shaders also cull materials that aren’t visible so we aren’t don’t a full screen pass for every material in the world.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2032.png" alt="Untitled" /></p>

<p>In our case we only have one nanite material so there is only a single draw</p>

<p><img src="/assets/img/posts/nanite/Untitled%2033.png" alt="Untitled" /></p>

<p>The pixel shader used for the fullscreen material pass is compiled from the material graph editor and is generated in much the same way as any other materials pixel shader. It is in these Nanite pixel shaders that the visibility buffer is resolved and all the pixel gradients are computed.</p>

<p>From this point on Nanite geometry is in the G-Buffer and identical to any other geometry as far as future lighting and shadows are concerned.</p>

<hr />

<h1 id="multiple-nanite-materials">Multiple Nanite Materials</h1>

<p>Lets make a new scene with 3 materials across 4 spheres. The two black spheres have the same material, the blue and white are different materials, all are Nanite meshes.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2034.png" alt="Untitled" /></p>

<p>All the Nantie geometry is rendered in a single API call, because the visibility buffer is independent of material, in this example everything is rendered by SW Rasterize.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2035.png" alt="Untitled" /></p>

<p>However now we have three different materials and the Nanite.MaterialResolve shows this. The two red spheres have the same material ID of zero, whereas the two yellow spheres are different, one has a material ID of 1 and the other 2.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2036.png" alt="Untitled" /></p>

<p>This is pretty much what you would expect from what we know about how Nanite resolves materials.</p>

<p>The material depth buffer is also what you would expect</p>

<p><img src="/assets/img/posts/nanite/Untitled%2037.png" alt="Untitled" /></p>

<p>The depth values are 0.00006, 0.00012 and 0.00018 for the three materials.</p>

<p>Up to here nothing is really any different regardless of the number of materials used in the scene. The base pass is where things are different, there is indeed one full-screen quad rendered per material.</p>

<p>These full-screen passes take about 20uS as a given material is only evaluated for pixels that use that material due to the depth test trick using the Material Depth buffer. In reality there needs to be a lot of expensive materials covering a lot of pixels for this stage to really be expensive but can happen.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2038.png" alt="Untitled" /></p>

<p>There is indeed a full screen pass per material</p>

<h1 id="wpo-materials">WPO Materials</h1>

<p>Let’s take the above scene and add a simple WPO calculation to the black material (left two spheres).</p>

<p><img src="/assets/img/posts/nanite/Untitled%2039.png" alt="Untitled" /></p>

<p>Once WPO is enabled on a Nanite mesh it is important to set the Max displacement in the material details panel. Any displacement above this amount is clamped. This is quite important for Nanite is its used to create maximum extent nodes that can be safely culled.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2040.png" alt="Untitled" /></p>

<p>You only need to specify this value if the WPO can make the object bigger, if it stays within its original bounds this value does not need to be set. Leaving this value at 0.0 disables clamping, any WPO offset is allowed, but it won’t modify any bounding volumes - incorrect culling and flickering can result.</p>

<blockquote>
  <p>None Nanite materials should set this too.</p>
</blockquote>

<p>The Nanite software renderer is a monolithic compute shader that does all the vertex processing, rasterization and pixel processing. For a non WPO material that vertex and pixel processing is always the same, hence why we can use a single draw for all materials. However, when WPO is enabled the vertex pipeline needs to be modified, the final position is no longer a simple transform but the result of the material graph. The base vertex code used by the HW vertex shaders and the SW compute shaders is NaniteVertexFactory.usf and this uses a function called GetMaterialWorldPositionOffset() which is by default an empty function.  When you create a WPO material, the code required for the WPO operation is injected in to GetMaterialWorldPositionOffset() and a new set of shaders is generated.</p>

<p>The WPO operation implemented in GetMaterialWorldPositionOffset() is called multiple times in the vertex factory because it needs velocity which means WPO is computed for this frame and last frame. Unlike the traditional renderer where velocity can be computed in the vertex shader and and passed to the pixel shader, Nanite must compute the velocity at each pixel which means the entire WPO graph has to be evaluated twice. The early velocity buffer cannot be used by WPO materials for local movement, final velocity is always computed at each pixel with the velocity buffer being combined with the local WPO velocity. Any WPO on Nanite should be a very simple function because of the number of evaluations.</p>

<blockquote>
  <p>For Nanite every different WPO material will be a different draw call.</p>
</blockquote>

<p>The first dispatch draws both the WPO objects in SW, yes multiple objects with the same material will draw at once. This is using the custom generated WPO SW Rasterize compute shader.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2041.png" alt="Untitled" /></p>

<p><img src="/assets/img/posts/nanite/Untitled%2042.png" alt="Untitled" /></p>

<p>The second dispatch draws the non WPO objects with the default nanite compute shader.</p>

<p><img src="/assets/img/posts/nanite/Untitled%2043.png" alt="Untitled" /></p>

<p><img src="/assets/img/posts/nanite/Untitled%2044.png" alt="Untitled" /></p>

<p>If we force HW rasterizing once again we still have 2 render passes, one for the WPO material and one for the none WPO material. For the HW path WPO generates a new pixel shader and vertex shader.</p>

<h1 id="fallback-mesh">Fallback Mesh</h1>

<p>Every Nanite mesh has a fallback mesh used for per poly collision, UV unwrapping, light baking, ray tracing etc. The fallback mesh is also used for rendering if nanite is disabled or not supported - this may be important for DX11 if that is the minimum spec PC.</p>

<p>On platforms that do support Nanite you can disable Nanite globally with <code class="language-plaintext highlighter-rouge">r.Nanite 0</code> and force all the fallback meshes to render, <code class="language-plaintext highlighter-rouge">r.Nanite.ProxyRenderMode 0</code> means render the fallback mesh if Nanite is not available, <code class="language-plaintext highlighter-rouge">r.Nanite.ProxyRenderMode 1</code> means don’t render nanite at all.</p>

<p>In the mesh editor there are options for specifying the resolution and quality of the fallback mesh, along with the ability to specify a custom fallback mesh/LODs. In a game that only runs on platforms that support Nanite a large memory saving can be had by setting the fallback mesh to be very low resolution or potentially nonexistent if none of the CPU side features are needed or data is supplied in other ways such as custom collision meshes.</p>

<h1 id="nanite-stats">Nanite Stats</h1>

<p>What do the primary Nanite stats mean and what are we looking for?</p>

<p><img src="/assets/img/posts/nanite/Untitled%203.png" alt="Untitled" /></p>

<p><code class="language-plaintext highlighter-rouge">main</code> and <code class="language-plaintext highlighter-rouge">post</code> refer to the two Nanite passes, the stats within the two blocks are the same. The main pass is the first pass that uses last frames HZB, the post pass is the geometry that wasn’t rendered last frame or its simply unsure about it. Ideally you want most geometry in the main pass.</p>

<p><code class="language-plaintext highlighter-rouge">pre-cull</code> is the number of instances before culling</p>

<p><code class="language-plaintext highlighter-rouge">post-cull</code> is the number of instances after the instance culling stage - visibile or partially visible instances.</p>

<p>The number of instances isn’t really a factor because they further broken down in to clusters. However, having uniform shapes that are easy to bound in a sphere or a screen space rectangle will help with rejecting instances.</p>

<p><code class="language-plaintext highlighter-rouge">Node visits</code> is the number of BVH nodes that were visited (part of the second stage culling in NodeAndClusterCulling). This will at least be the number of instances because every instance has at least one BVH node. You don’t have much control over this because the BVH for an instance is built for you.</p>

<p><code class="language-plaintext highlighter-rouge">candidates</code> this is the number of candidate render clusters prior to cluster culling.</p>

<p><code class="language-plaintext highlighter-rouge">ClustersSW</code> The number of clusters rendered by the software compute path. Keeping triangles within a cluster a consistent size will make the cluster render quicker.</p>

<p><code class="language-plaintext highlighter-rouge">ClustersHW</code> The number of clusters rendered by the hardware rasterizer (traditional GPU). Lots of clusters in here indicate large triangles that aren’t ideal for Nanite.</p>

<p><code class="language-plaintext highlighter-rouge">Clusters</code> The total number of clusters rendered via any path</p>

<p>The total section is the sum of the main and post passes.</p>

<p><code class="language-plaintext highlighter-rouge">Clusters</code> is the total number of clusters in the entire frame (summed across the 4 passes, HW+SW from main and post).</p>

<p><code class="language-plaintext highlighter-rouge">Tris</code> total number of triangles in the rendered clusters</p>

<p><code class="language-plaintext highlighter-rouge">Verts</code> total number of verts in the rendered clusters.</p>

<h1 id="nanite-overview-visualizer">Nanite Overview visualizer</h1>

<p><img src="/assets/img/posts/nanite/Untitled%2045.png" alt="Untitled" /></p>

<p>A lot of these are self explanatory.</p>

<p><code class="language-plaintext highlighter-rouge">Evaluate WPO</code> This shows what materials use WPO. Green has WPO, red doesn’t.  You want lots of red here. If there is green make sure they use a minimal number of WPO materials so you aren’t switching shaders all the time.</p>

<p><code class="language-plaintext highlighter-rouge">Material ID</code> show the total number of Nanite materials. Remember Nanite performs a full screen pass for every material, there every different color in this view is a full screen pass to lay down the G-Buffer. Use this with the <code class="language-plaintext highlighter-rouge">Evaluate WPO</code> view to see how many WPO materials are being used.</p>

<p><code class="language-plaintext highlighter-rouge">Raster bins</code> is how the scene was grouped in to bins which represent batches of geometry. It could be a single bin but is typically 4, one for each of HW+SW in main and post passes. WPO will seriously mess this up especially if there are lots of WPO materials.</p>

<p><code class="language-plaintext highlighter-rouge">Overdraw</code> This is a big one to check when looking for performance problems. Nanite only supports opaque geometry so in theory it should all nicely occlude and there should be minimal overdraw. This is mostly true but Nanite supports masked alpha which messes with the culling and it’s possible to make geometry that is difficult to cull. Remember it is clusters that are culled in the HZB not triangles therefore if any part of the cluster is visible the entire 128 triangle cluster is rendered. This makes things like foliage very difficult to cluster cull and you’ll see the overdraw and the number of rendered clusters go through the roof.   Why is foliage problematic to render? First of all, it’s difficult to make 128 triangle clusters that have nice shape when projected into screen space - this makes getting false positives for visibility really easy. Second, it’s easy to get to holes in the depth buffer where a single pixel of the back plane or distant geometry is visible, these depth holes, even one pixel in size, push the HZB back to the farthest visible distance.  When the mips of the HZB are generated, the output pixel is the furthest of all the input pixels, this makes the small HZB levels almost useless for culling as the farthest distance in any HZB pixel is the distant geometry or back plane.</p>

<h1 id="debug-rendering">Debug Rendering</h1>

<p>Nanite has a lot of debug modes and visualizers in the editor. Some of the debug features force shaders to output to multiple frame buffers when they technically don’t need to. Any profiling should be done in a full retail build where these features will be disabled.</p>]]></content><author><name>Rob</name></author><category term="[&quot;blog&quot;, &quot;graphics&quot;]" /><summary type="html"><![CDATA[A deep dive in to Unreal5 and Nanite, how does it work?]]></summary></entry><entry><title type="html">Windows thread scheduling</title><link href="https://trickybitsblog.github.io/2024/04/19/scheduling.html" rel="alternate" type="text/html" title="Windows thread scheduling" /><published>2024-04-19T00:00:00-06:00</published><updated>2024-04-19T00:00:00-06:00</updated><id>https://trickybitsblog.github.io/2024/04/19/scheduling</id><content type="html" xml:base="https://trickybitsblog.github.io/2024/04/19/scheduling.html"><![CDATA[<p>Windows has never claimed to be a real time operating system but in reality its not even a timely operating system.</p>

<p>This is a quick post as a follow up to the <a href="/2024/02/25/timestamps.html">previous post on windows timers</a>. As we saw in that post the period of the windows kernel interval interrupt is quite variable these interrupts are the engine that steps Windows forward. Within Windows the kernel interval period affects more than just jitter on various timer APIs, it changes the rate of thread scheduling, the <code class="language-plaintext highlighter-rouge">Sleep</code> API, WM_TIMER messages and waitable timers.</p>

<p>For example, if you execute <code class="language-plaintext highlighter-rouge">Sleep(1)</code> to suspend execution for 1ms, you might not wake up for 15.625ms.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="c1">//assume QPC is 10Mhz for this example</span>
    <span class="kt">uint64_t</span> <span class="n">start</span><span class="p">;</span>
    <span class="n">QueryPerformanceCounter</span><span class="p">((</span><span class="n">LARGE_INTEGER</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">start</span><span class="p">);</span>

    <span class="n">Sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

    <span class="kt">uint64_t</span> <span class="n">end</span><span class="p">;</span>
    <span class="n">QueryPerformanceCounter</span><span class="p">((</span><span class="n">LARGE_INTEGER</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">end</span><span class="p">);</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">"%f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="p">(</span><span class="kt">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="mi">10000</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Running this loop without setting the timer interval resolution you’ll get results like what is shown below. The actual interval bounces around and the closest we got to what we asked for is 3ms. Remember the kernel interval is a system wide setting, set to whatever is the minimum request from all running processes.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>15.3901
15.0397
15.2044
3.0466
15.5567
15.5170
</code></pre></div></div>

<p>Running the exact same code after calling <code class="language-plaintext highlighter-rouge">NtSetTimerResolution</code> to force the interval period to the allowed minimum, which on this machine is 0.5ms, it actually does sleep for the 1ms asked for and it does so quite accurately but only because the sleep period is a multiple of the 500uS timer interval.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.0230
1.0214
1.0210
1.0213
1.0210
</code></pre></div></div>

<p>Remember all of these tests are on an unloaded system so there are no scheduling conflicts and increasing thread priority makes no difference.</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">Sleep(0)</code> is not affected by the timer period because it simply yields the current time slice, it has nothing to do with elapsed time, this is the way to yield on a Windows machine. The calling thread never leaves the runnable state and the <code class="language-plaintext highlighter-rouge">Sleep(0)</code> call typically returns in 2-3 microseconds on system that has available processor time, if there isn’t a processor available or there are other threads with higher priority, you might have to wait for the full interval period or longer. If you want to play nice then having <code class="language-plaintext highlighter-rouge">Sleep(0)</code> in a tight loop is better than just spinning and burning CPU cycles. Remember if your thread waits 15ms by chance it could have a drastic effect on game frame timing.</p>
</blockquote>

<hr />

<p>Lets see what OSX and Linux do with a similar test.</p>

<h3 id="osx">OSX</h3>

<p>Using OSX Sonoma 14.4.1 (23E224), on a M1 Max and the following code:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="c1">//time_ns is a 64bit utility wrapper for clock_gettime(CLOCK_MONOTONIC)</span>
    <span class="kt">uint64_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">time_ns</span><span class="p">();</span>
    <span class="n">usleep</span><span class="p">(</span><span class="mi">1000</span><span class="p">);</span>
    <span class="kt">uint64_t</span> <span class="n">end</span> <span class="o">=</span> <span class="n">time_ns</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"%f</span><span class="se">\n</span><span class="s">"</span><span class="p">,((</span><span class="kt">double</span><span class="p">)</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="mf">1e6</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Sleeping for 1ms yields the following when locked to a P-Core.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.259750
1.259791
1.254250
1.259042
1.264125
1.269500
</code></pre></div></div>

<p>OSX is 25% over the requested delay but it is very consistent. Its interesting that Windows is actually more accurate than OSX when sleeping for 1ms when the interval timer is set to 0.5ms but this is only true is the sleep period is a multiple of the interval period.</p>

<p>Sleeping for 300uS on a P-Core yields the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.384875ms
0.380625ms
0.379500ms
0.385500ms
0.386208ms
0.381750ms
</code></pre></div></div>

<p>Again very consistent but approximately 25% high. On an E-Core it is not as accurate or consistent but I haven’t looked in to it any closer.</p>

<h3 id="linux">Linux</h3>
<p>Using Ubuntu 22.04 on kernel 6.2.0-39, 16 core Ryzen7, the code is identical to OSX.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="c1">//time_ns is a 64bit wrapper for clock_gettime(CLOCK_MONOTONIC)</span>
    <span class="kt">uint64_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">time_ns</span><span class="p">();</span>
    <span class="n">usleep</span><span class="p">(</span><span class="mi">1000</span><span class="p">);</span>
    <span class="kt">uint64_t</span> <span class="n">end</span> <span class="o">=</span> <span class="n">time_ns</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"%f</span><span class="se">\n</span><span class="s">"</span><span class="p">,((</span><span class="kt">double</span><span class="p">)</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="mf">1e6</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Sleeping for 1ms yields the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.081928
1.078950
1.082176
1.080142
1.080684
</code></pre></div></div>

<p>and sleeping for 300uS</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.353397
0.353522
0.353417
0.353463
0.353513
</code></pre></div></div>

<p>Although technically Windows was more accurate for 1ms delay when the interval was set to 500uS, Linux is still the clear winner, its both very accurate and very consistent in all cases tested. Even if the system start to bog down it’s still very consistent although the accuracy drops. Windows is all over the place when you bog the system down. OSX was pretty decent too but the E-Cores need some investigation.</p>

<p>The sub millisecond tests aren’t even possible on Windows. In general if you need microsecond delays on Windows, spin the CPU in a loop using QueryPerformanceCounter, and maybe <code class="language-plaintext highlighter-rouge">Sleep(0)</code> to yield if you want to play nice. If you need really accurate delays and can’t handle the odd spike then don’t yield the CPU as there is always a chance you might not be back for 15+ms, even on multi-core systems. Threaded job managers should also think twice about unnecessarily yielding the CPU.</p>

<p>I don’t know why windows continues to have a kernel timer that continually changes period. I also don’t know why the entire operating system uses the same timer. It probably made sense years ago but on modern multi-processor machines with multiple hardware timers it makes no sense. Its just another way the windows kernel is showing its age. This also explains why Windows doesn’t have a microsecond sleep API. It would be pointless because it can’t reliably sleep for milliseconds.</p>]]></content><author><name>Rob</name></author><category term="[&quot;blog&quot;, &quot;windows&quot;]" /><summary type="html"><![CDATA[Windows time and thread scheduling]]></summary></entry><entry><title type="html">Measuring HDMI Latency</title><link href="https://trickybitsblog.github.io/2024/03/07/hdmi-latency-tester.html" rel="alternate" type="text/html" title="Measuring HDMI Latency" /><published>2024-03-07T00:00:00-07:00</published><updated>2024-03-07T00:00:00-07:00</updated><id>https://trickybitsblog.github.io/2024/03/07/hdmi-latency-tester</id><content type="html" xml:base="https://trickybitsblog.github.io/2024/03/07/hdmi-latency-tester.html"><![CDATA[<p>Managing display latency plays a big role in the architecture of game engines, video playback and display systems in general. In a typical consumer environment there is one component that we have little to no control over; the TV. Modern TVs and monitors have an unknown and undocumented latency between a frame being received and displayed - this is the latency we want to measure and in this post we are going to make a HDMI latency tester with a Raspberry Pi.</p>

<hr />

<h2 id="hdmi-history-lesson">HDMI History Lesson</h2>

<p>As usual with my posts… A bit of history</p>

<p>HDMI is a raster order, scanning format, in much the same way as NTSC or VGA. In fact HDMI has its roots in VGA.  VGA consists of 3 analog signals, 1 for each of R,G and B, and 2 quasi digital signals for HSYNC and VSYNC. VGA has overscan areas in the signal, just like NTSC, and for the same reasons; mostly due to sync and settling time within the older analog monitors. As the display resolution increased, the bandwidth of the analog signals increased to a point where it barely worked, the result of band limiting analog video is a blurry image. Even with the best analog signal processing and the best cables, it was still blurry, the only solution was to switch to digital in the form of <a href="https://glenwing.github.io/docs/DVI-1.0.pdf">DVI</a>.</p>

<p>Early DVI ports (DVI-I) carried the analog VGA signals along side the digital signals. The analog and digital signals had identical timing, the digital signal was taken before the DAC and the analog was after it. The structure and timing of the frame was the same between analog and digital, the digital signal had the same overscan areas and the same sync timing as the analog signal.  DVI has no explicit sync signals. On any given pixel clock DVI encodes either pixel data or control data. The control data is limited to 6 bits and is transmitted as 2 bits per color channel, these bits are typically called C0 and C1. DVI only uses the 2 bits on channel 0 (the blue channel), where C0 and C1 are used to indicate HSYNC and VSYNC.</p>

<p><a href="https://engineering.purdue.edu/ece477/Archive/2012/Spring/S12-Grp10/Datasheets/CEC_HDMI_Specification.pdf">HDMI 1.0</a> is backwards compatible with DVI and it uses the same signalling on the 3 color channels, and the same sync information. HDMI 1.0 used the additional C0C1 bits on the red and green channels to mark video vs data, HDMI calls these video islands and data islands. Data islands are typically used to transmit audio but there are a handful of other things listed in the spec, data islands utilize the unused pixels within the overscan areas of the signal. HDMI 2.0 is an entirely different animal.</p>

<p>All the original DVI resolutions were PC-esq resolutions, things like 1024x768 or 800x600 and are typically called DMT (Display Monitor Timing) modes and defined by VESA. HDMI is quite strict in the timing it supports due to the sync areas being used for other things and defines a different set of modes more typical for consumer TV, resolutions like 1920x1080 and 1280x720 along with all the older NTSC/PAL resolutions, these are typically called CEA-861 modes as they are defined by the Consumer Electronics Association. The only difference between the two sets of modes is pixel timing, there is no flag to indicate its one of the other.</p>

<p>Lets look at some <a href="https://tomverbeure.github.io/video_timings_calculator">timing examples</a>. For digital video one pixel is sent per clock cycle, horizontal timing is measured in pixel clocks, vertical timing is in lines. Using 1080p from the table below as an example: There are 2200x1125 total pixels, and at 60Hz this equates to 148.5 million pixels per second which happens to be the pixel clock rate.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: center">3480x2160p60</th>
      <th style="text-align: center">1920x1080p60</th>
      <th style="text-align: center">640x480p60</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pixel Clock</td>
      <td style="text-align: center">594 MHz</td>
      <td style="text-align: center">148.5 MHz</td>
      <td style="text-align: center">25.175 MHz</td>
    </tr>
    <tr>
      <td>Pixel Time</td>
      <td style="text-align: center">1.7 ns</td>
      <td style="text-align: center">6.7 ns</td>
      <td style="text-align: center">39.7 ns</td>
    </tr>
    <tr>
      <td>Horizontal Freq.</td>
      <td style="text-align: center">135.0 kHz</td>
      <td style="text-align: center">67.500 kHz</td>
      <td style="text-align: center">31.469 kHz</td>
    </tr>
    <tr>
      <td>Line Time</td>
      <td style="text-align: center">7.407μs</td>
      <td style="text-align: center">14.815 μs</td>
      <td style="text-align: center">31.778 μs</td>
    </tr>
    <tr>
      <td>Vertical Freq.</td>
      <td style="text-align: center">60.000 Hz</td>
      <td style="text-align: center">60.000 Hz</td>
      <td style="text-align: center">59.94Hz</td>
    </tr>
    <tr>
      <td>Frame Time</td>
      <td style="text-align: center">16.667 ms</td>
      <td style="text-align: center">16.667 ms</td>
      <td style="text-align: center">16.683 ms</td>
    </tr>
    <tr>
      <td>Active Pixels</td>
      <td style="text-align: center">3840</td>
      <td style="text-align: center">1920</td>
      <td style="text-align: center">640</td>
    </tr>
    <tr>
      <td>H Front Porch</td>
      <td style="text-align: center">176</td>
      <td style="text-align: center">88</td>
      <td style="text-align: center">16</td>
    </tr>
    <tr>
      <td>H Sync Width</td>
      <td style="text-align: center">88</td>
      <td style="text-align: center">44</td>
      <td style="text-align: center">96</td>
    </tr>
    <tr>
      <td>H Back Porch</td>
      <td style="text-align: center">296</td>
      <td style="text-align: center">148</td>
      <td style="text-align: center">48</td>
    </tr>
    <tr>
      <td>H Blanking Total</td>
      <td style="text-align: center">280</td>
      <td style="text-align: center">280</td>
      <td style="text-align: center">160</td>
    </tr>
    <tr>
      <td>Total Pixels</td>
      <td style="text-align: center">4400</td>
      <td style="text-align: center">2200</td>
      <td style="text-align: center">800</td>
    </tr>
    <tr>
      <td>Active Lines</td>
      <td style="text-align: center">2160</td>
      <td style="text-align: center">1080</td>
      <td style="text-align: center">480</td>
    </tr>
    <tr>
      <td>V Front Porch</td>
      <td style="text-align: center">8</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">10</td>
    </tr>
    <tr>
      <td>V Sync Width</td>
      <td style="text-align: center">10</td>
      <td style="text-align: center">5</td>
      <td style="text-align: center">2</td>
    </tr>
    <tr>
      <td>V Back Porch</td>
      <td style="text-align: center">72</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">33</td>
    </tr>
    <tr>
      <td>V Blanking Total</td>
      <td style="text-align: center">90</td>
      <td style="text-align: center">45</td>
      <td style="text-align: center">45</td>
    </tr>
    <tr>
      <td>V Blank Duration</td>
      <td style="text-align: center">667 μs</td>
      <td style="text-align: center">667 μs</td>
      <td style="text-align: center">1430 μs</td>
    </tr>
    <tr>
      <td>Total Lines</td>
      <td style="text-align: center">2250</td>
      <td style="text-align: center">1125</td>
      <td style="text-align: center">525</td>
    </tr>
    <tr>
      <td>Active Pixels</td>
      <td style="text-align: center">8,294,400</td>
      <td style="text-align: center">2,073,600</td>
      <td style="text-align: center">307,200</td>
    </tr>
    <tr>
      <td>Unused Pixels</td>
      <td style="text-align: center">1,605,600</td>
      <td style="text-align: center">401,400</td>
      <td style="text-align: center">112,800</td>
    </tr>
  </tbody>
</table>

<p>Visualizing the full frame for 1080p gives this:</p>

<p><a data-lity="" class="sx-center"><img src="/assets/img/posts/march-2024/1080p.png" /></a></p>

<p>While none of this is directly relevant to measuring latency, it is important to know the full frame structure, there are significant portions that are not visible and need to account for them in any timing calculations.</p>

<blockquote>
  <p>A significant amount of data can be stuffed in the unused areas of the signal, especially for the high resolution modes. 4K has 1.6 millions unused pixels per frame, in theory this equates to 96 MBytes of data per second but the actual throughput is actually much less, especially on pre HDMI2.0, as data islands are sent at 4 bits per pixel clock per channel, and not all of the unused area can carry data. However it’s still a significant amount of data. Lower resolutions have fewer unused pixels and therefore can carry less data - 32 PCM audio channels are not possible on 640x480 video.</p>
</blockquote>

<hr />

<h2 id="where-does-the-display-latency-come-from">Where does the display latency come from?</h2>

<p>The primary reason is because modern flat panel TVs support multiple input types with multiple resolutions and update frequencies, all of these inputs are decoupled from the native resolution and update characteristics of the physical display panel.  The TV buffers the incoming signal to memory where it can be manipulated in software, it can be filtered, de-interlaced and scaled to native resolution independently of the input source or resolution. Color conversion and correction can be applied, Smart TV applications and on screen menus can be rendered on top, even other inputs can be overlaid as picture in picture before the final image is sent to the display.  All of this processing takes time! While watching a movie the display latency isn’t much of a problem but for video games it can be a big issue when the display is lagging behind your button presses. In the early days of HD it was a problem for movies too because some TVs would delay the video but not the audio!</p>

<p>Why do some TVs take 10ms and some take 100ms is simply down to architecture of the display stack and how much it was optimized, along with how many pixels are being processed, what sort of processing is being done, how much of the display pipeline is hardware vs software. Some high end TVs have higher latency than you might expect simply because they do more processing on more pixels and processing power doesn’t scale the same. A lot of displays, especially TVs, have a game mode or low latency mode which is supposed to reduce end to end latency at the expense of some features being disabled.</p>

<p>Having a complete frame in memory, with all the pixels ready for display, is what enables a high end display to have 4ms update time - this time is just how long it takes the display panel to update and it can only update this fast if it has a whole frame ready. The fact the physical panel can be updated 4 times in the time it takes to receive one frame is where features such as 60Hz to 120Hz frame interpolation comes from. A modern smart TV is literally an embedded linux device that runs embedded image processing software nad has a capture card on the front end.</p>

<blockquote>
  <p>HDMI 2.1 has a few features to reduce latency, specifically Variable Refresh Rate (VRR) and Quick Frame Transport (QFT), which bursts a frame across the HDMI link at the maximum pixel clock supported (still in raster order). Utilizing these features, a TV that supports 4K60, should be able to transfer a 1080p frame in 4.15ms or a 720p frame in 1.85ms and still display at 60Hz.</p>
</blockquote>

<p>In the old analog days there was no latency because the input signal directly controlled the raster beam of the TV. The typical latency of an analog TV was maybe a microsecond or two as this is how long it took for the input signal to propagate through the electronics.</p>

<p>TVs with buffering, image processing, and the associated latency are here to stay so lets measure it!</p>

<hr />

<h2 id="how-do-we-measure-latency">How do we measure latency?</h2>

<p>In theory all we have to do is switch between a black screen to a white screen while timing how long it takes a phototransistor placed against the display to detect the white light (any two screens where you can detect the difference can be used, pure black and pure white are the easiest). In practice it’s a little more difficult because you need precise control of the display hardware because you need to know exactly where in the video signal you are, you also need a low latency IO system to which you can connect the photo transistor.  On a typical PC there is no direct IO and USB will just add to the latency and make the hardware more complex. Without being in kernel mode and hacking around in the display driver its hard to know exactly what the display hardware is doing, outside of Linux you’ll probably never know what the display hardware is doing. A non-PC approach seems best.</p>

<p>My first attempt at measuring TV input latency wasn’t for HDMI at all, but for analog inputs, and I simply bit banged a composite NTSC signal on a miro controller; if you only need black and white this is pretty trivial. For HDMI bit banging is not so trivial because the bit clock is an order of magnitude greater than the pixel clock, the bit clock for 1080P is 1.485GHz. These speeds are out of the range of most FPGAs and very much out of range of software bit banging - <a href="https://github.com/Wren6991/picodvi">although it has been done at lower resolutions with creative use of a RP2040</a>. A lot of FPGAs have HDMI support and do all the serializing in a dedicated hardware, these tend to be expensive and even if they aren’t, they are complicated and require multi layer circuit boards. The goal of this project was for anybody to cheaply and easily measure latency. A simpler FPGA might not have HDMI blocks but could drive something like an ADV7511 HDMI encoder which takes parallel 24bit RGB pixel bus data. This did work all the way up to 1080p but it was a lot of complex hardware to simply output black or white.</p>

<p>Finally, I experimented with bare metal on a Raspberry Pi and after some experimenting it works awesome and I have a lot better understanding of how the Pi hardware works. The Pi also has lots of high speed IO making it trivial to interface with a phototransistor.</p>

<p>As an extra bonus, because the Pi can generate composite NTSC/PAL, and because these old analog formats use the same display hardware as hdmi, we can measure latency on the analog TV inputs with the exact same code!</p>

<hr />

<h2 id="raspberry-pi-display-hardware">Raspberry PI display hardware</h2>

<p>For the rest of this article, I’m going to use a Raspbery Pi 3 B+ because its the one I had handy, however it can only output resolutions up to 1080p (maybe a little over if you overclock it). If you want to test 4K latency then at least a Pi4 would be needed and it will require code changes as the Pi4 hardware is slightly different. I’ll be using bare metal to keep the code as simple and clean as possible and we don’t have to fight with the operating system. Fortunately we can do everything with the display hardware and don’t need to deal with the complexity of the VideoCore GPU. To keep things even more simple lets use the standard boot code and <a href="https://elinux.org/RPi_Configuration">configuration file to set the video mode</a> and then hijack the hardware we need later. Using the boot code means there are only two display components we care about:  Pixel Value (PV), and Hardware Video Scalar (HVS) and both are quite easy to understand.</p>

<blockquote>
  <p>By directly setting the video mode we can ignore what the TV says it supports via EDID. Your milage may vary but all the TVs I tried will display modes that are not listed in the EDID data. Monitors seem even more flexible. The old Dell U2713HM used for testing this project reports 1080p and 720p as the only HD modes supported over HDMI. However in testing it will display all the same PC modes that it supports over Display Port.</p>
</blockquote>

<p>The example code for this project only supports HDMI and Analog SDTV, it does not support the other outputs such as DPI/DSI although its not a big change to support these. In addition to display hardware TIMER_LO is used as a micro second timestamp, although its a 64bit counter, only the bottom 32bits are used.</p>

<h4 style="color: gray" id="pixel-value-pv">Pixel Value (PV)</h4>

<p>PV is a hardware block that sits at the front of the encoders and counts pixel clocks to track where we are in the frame, whether we are scanning active or inactive areas etc. When scanning out an active area of the frame PV asks HVS for pixel data. The PV hardware only has a few registers, which we will read, but it will be programmed by the boot code to match the output encoder. The most useful thing that PV does for us is to generate interrupts for things like hsync, vsync, and most importantly, PV can generate an interrupt at the start of active video. Start of active video is when the first visible pixel is being output. From empirical testing there pretty much no latency between the PV indicating the start of active video and the pixels appearing on the HDMI signal.</p>

<p>When we switch from the black frame to the white frame, start of active video is the first instant the white pixels could be visible, this is when we start our timer and any delay before the white is visible is latency within in the TV!</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">pixel_valve</span> 
<span class="p">{</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">c</span><span class="p">;</span>            <span class="c1">//bit2/3 control the clock src and which of HDMI/SDTV is being output</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">vc</span><span class="p">;</span>           <span class="c1">//bit4 is set when interlaced</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">vsyncd_even</span><span class="p">;</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">horza</span><span class="p">;</span>        <span class="c1">//HBP and HSYNC clocks</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">horzb</span><span class="p">;</span>        <span class="c1">//HFP and ACTIVE clocks (hactive is the width)</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">verta</span><span class="p">;</span>        <span class="c1">//VBP and VSYNC lines</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">vertb</span><span class="p">;</span>        <span class="c1">//VFP and V ACTIVE lines (vactice is the height)</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">verta_even</span><span class="p">;</span>   <span class="c1">//same data as verta and vertb but for the even frame when interlaced</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">vertb_even</span><span class="p">;</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">int_enable</span><span class="p">;</span>   <span class="c1">//interrupt enables</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">int_status</span><span class="p">;</span>   <span class="c1">//interrupt status </span>
<span class="p">};</span>

<span class="c1">//The available interrupts are as follows (the horizontal interrupts are very high frequency)</span>
<span class="cp">#define PV_INTEN_HSYNC_START (1&lt;&lt;0)     //start of horizontal sync
#define PV_INTEN_HBP_START   (1&lt;&lt;1)     //start of horizontal back porch
#define PV_INTEN_HACT_START  (1&lt;&lt;2)     //start of horizontal active
#define PV_INTEN_HFP_START   (1&lt;&lt;3)     //start of horizontal front porch
#define PV_INTEN_VSYNC_START (1&lt;&lt;4)     //start of vertical sync
#define PV_INTEN_VBP_START   (1&lt;&lt;5)     //start of vertical back porch
#define PV_INTEN_VACT_START  (1&lt;&lt;6)     //start of vertical active (visible line0)
#define PV_INTEN_VFP_START   (1&lt;&lt;7)     //start of vertical front porch
#define PV_INTEN_VFP_END     (1&lt;&lt;8)     //end of vertical front porch
#define PV_INTEN_IDLE        (1&lt;&lt;9)     //idle
</span></code></pre></div></div>

<p>Although PV can generate interrupts, this project isn’t going to use actual CPU interrupts. We can keep CPU interrupts globally disabled, enable interrupts within PV which will cause it to update the interrupt status registert and then we’ll poll the interrupt status register to see what is going on. Polling should be much lower latency than handling an interrupt and there is much less jitter. We’ll use code like the following to wait for active video:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="c1">//volatile register - read it once so we see consistent data</span>
    <span class="kt">uint32_t</span> <span class="n">stat</span> <span class="o">=</span> <span class="n">pv</span><span class="o">-&gt;</span><span class="n">int_status</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">stat</span> <span class="o">&amp;</span> <span class="n">PV_INTEN_VACT_START</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="c1">//read the time in microseconds</span>
      <span class="n">start_time</span> <span class="o">=</span> <span class="n">Read32</span><span class="p">(</span><span class="n">TIMER_LOW</span><span class="p">);</span>  <span class="c1">//read time from 0x3f003004;</span>

      <span class="c1">//clear status flags by writing 1's (this will clear all pending interrupts)</span>
      <span class="n">pv</span><span class="o">-&gt;</span><span class="n">int_status</span> <span class="o">=</span> <span class="n">stat</span><span class="p">;</span>
      <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>The above details show why its important to understand the video hardware as the structure of a frame. If we were to use vsync instead of active video for the start timer, and remember vsync is all that maybe available on some hardware, then a significant error correction has to be applied. At 1080p vsync occurs 41 lines before the first visible pixel, at 14.815us per line this equates to 607.414 μs. At 640x480 the time from the start of vsync to the first visible pixel is over a millisecond, 1112.23 μs to be exact! Fortunately the time between vsync and the first pixel is consistent so can be accounted for if the exact mode timing is known. Utilizing the start of active video interrupt is a convenient way of not having to deal with it.</p>

<p>The Pi3 has 3 different PV blocks, PV2 is the one that we’ll use as it drives both the HDMI and SDTV encoders. The others are for DSI/DPI displays supported by the Pi and all 3 PVs can be used at the same time and display different content.</p>

<h4 style="color: gray" id="hardware-video-scalar-hvs">Hardware Video Scalar (HVS)</h4>

<p>HVS is DMA driven compositor and it doesn’t know anything about timing or output signals, it generates pixels on demand sends it to the PV for output, there are in effect 3 compositors within HVS, each drives one of the PVs. For HDMI and SDTV we shall use HVS channel 1.</p>

<p>HVS is maybe the most flexible hardware compositor I’ve ever seen on any video hardware, you could make a 2D game utilizing just HVS. It takes a <a href="https://blog.benjdoherty.com/2019/05/21/Exploring-Hardware-Compositing-With-the-Raspberry-Pi/">display list that describes a set of frame buffers that make up the composition</a>, the final composited result is not stored anywhere, it is onlt sent to PV to be ouput. The frame buffers that are composited can be any size, at any location on the screen, in different color formats, scaled, overlaid and alpha blended together. Each channel within HVS has a single register that sets the base address of the current display list. The display list memory lives in the HVS hardware and is only 4K in size, this 4K of display list memory is shared between all HVS channels currently in use.</p>

<p>A none scaled frame buffer only consumes 7 32bit words in display list memory so even if all PVs are enabled and outputting different content there should be plenty of memory to go around.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">//the fixed address of the 4K of dl memory</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span><span class="o">*</span> <span class="n">dlist_memory</span> <span class="o">=</span> <span class="p">(</span><span class="k">volatile</span> <span class="kt">uint32_t</span><span class="o">*</span><span class="p">)</span><span class="mh">0x3f402000</span><span class="p">;</span>
  
  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="c1">//Control word/flags/format etc</span>
  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="c1">//x pos, ypos and alpha</span>
  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="c1">//width and height</span>
  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="c1">//dummy used by HVS</span>
  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="c1">//frame buffer memory address</span>
  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="c1">//dummy used by HVS</span>
  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="c1">//line stride bytes</span>

  <span class="n">dlist_memory</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span> <span class="o">=</span> <span class="mh">0x80000000</span><span class="p">;</span>   <span class="c1">//end</span>

  <span class="c1">//display list for channel 1 starts at offset 0</span>
  <span class="c1">//this will take effect on the next vsync</span>
  <span class="n">write32</span><span class="p">(</span><span class="n">DISPLIST1</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</code></pre></div></div>

<p>The HVS hardware reads the display list register at the start of the next frame, any changes to the register don’t take effect until then. Changing the display list while its being used will cause problems.</p>

<p>For the HDMI tester one option is to have two precomputed full screen display lists, one that fills the screen with black and the other than fills it with white, then change DISPLIST1 to point at either the white or black list. This does work but there is a better way…Each HVS channel has a control block and in that control block are a number of very useful registers.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">hvs_channel</span> <span class="p">{</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">dispctrl</span><span class="p">;</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">dispbkgnd</span><span class="p">;</span>   <span class="c1">// xxRRGGBB, bit 24 is bg enable</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">dispstat</span><span class="p">;</span>    <span class="c1">//0:11 line, 12:17 frame, 28 empty, 29 full, 30:31 mode</span>
  <span class="k">volatile</span> <span class="kt">uint32_t</span> <span class="n">dispbase</span><span class="p">;</span>
<span class="p">};</span>

<span class="c1">//pi3 address for the hvs channel control blocks</span>
<span class="k">volatile</span> <span class="k">struct</span> <span class="nc">hvs_channel</span><span class="o">*</span> <span class="n">hvs</span><span class="o">=</span><span class="p">(</span><span class="k">volatile</span> <span class="k">struct</span> <span class="nc">hvs_channel</span><span class="o">*</span><span class="p">)</span><span class="mh">0x3f400040</span><span class="p">;</span>
</code></pre></div></div>

<p>The interesting registers are <code class="language-plaintext highlighter-rouge">dispbkgnd</code> and <code class="language-plaintext highlighter-rouge">dispstat</code>. <code class="language-plaintext highlighter-rouge">dispbkgnd</code> is the backgrounf color and is used for any pixels not covered by a buffer, if we have an empty display list then the whole screen will be the background color and the background color is a live register, it is sampled every time HVS generates a new line and can be changed on the fly outside of vsync. The bottom 12 bits of <code class="language-plaintext highlighter-rouge">dispstat</code> tells us what line HVS is currently generating. This counter has a quirk and it stops at active height when its finished generating the last visible line. This is super useful as when HVS has finished generating the last line we can make changes to the background color in plenty of time for it to be displayed next frame with changing what is currently displayed.</p>

<p>There is no official documentation on any of this display hardware, most of the above has been reverse engineered or derived from other projects. Addition information on HVS, PV, HDMI, SDTV and general bare metal programming can be found at <a href="https://github.com/librerpi/lk/tree/vc4/platform/bcm28xx">the Pi version of little kernel</a>, <a href="https://github.com/rsta2/circle">The Circle Project</a> or <a href="https://www.kernel.org/doc/html/latest/gpu/vc4.html">the linux drm driver for VC4</a></p>

<hr />

<h2 id="software">Software</h2>

<p>All the source code and build instructions can be found in our <a href="https://github.com/TrickyBitsBlog/hdmi-latency">github repo</a></p>

<p>The basic idea is pretty trivial now the hardware is figured out. The basic outline is:</p>

<ul>
  <li>
    <p>Obtain settings and display size from PV and HSV registers, we didn’t configure the mode so we’ll figure out what was configured by the bootcode and config file.</p>
  </li>
  <li>
    <p>Set the background color to black for a few seconds to let things settle</p>
  </li>
  <li>
    <p>Wait for HVS status to indicate the last line, change the background color to white which will be visible on the next frame.</p>
  </li>
  <li>
    <p>Wait in a tight loop for PV status to show start of active scan out, take the starting time</p>
  </li>
  <li>
    <p>Wait in a tight loop for the photo sensor to pull GPIO 24 (pin18) low, this indicates the phototransistor has detected light, take a stop time stamp</p>
  </li>
  <li>
    <p>Render the result to the frame buffer, turn the background back to black and repeat</p>
  </li>
</ul>

<hr />

<h2 id="hardware">Hardware</h2>

<p>The only external hardware is a 100K variable resistor and a <a href="https://www.mouser.com/ProductDetail/Lite-On/LTR-4206?qs=r9xH5VET0K7MdqUlHjZTQQ%3D%3D">LTR-4206</a> phototransistor:</p>

<p><a data-lity="" class="sx-center"><img src="/assets/img/posts/march-2024/schematic.png" /></a></p>

<p>connected to the PI as follows:</p>

<p><a data-lity="" class="sx-center"><img src="/assets/img/posts/march-2024/pins.png" /></a></p>

<p>The higher the resistance the more sensitive the transistor is to light, typically about 50k gives reliable results for a typical TV (a 50K fixed resistor could be used in most cases, I only used a variable resistor in order to tweak it). The LTR-4206 has a fairly narrow sensitivity window but it will detect ambient light from the sides which could give erroneous readings. The transistor needs to be shrouded so it only detects light directly in front of it. Electrical tape around the sides of transistor will work but you could also 3D print something more professional.</p>

<p>Here is a photo of my ghetto setup with the three leads that connect to the Pi.</p>

<p><a data-lity="" class="sx-center"><img src="/assets/img/posts/march-2024/p2.jpeg" /></a></p>

<p>You don’t have to use the LTR-4206, you can pretty much use any phototransistor but some aren’t great at directly driving a GPIO in this configuration, they work but output a voltage in the digital forbidden zone and results won’t be reliable. You need the voltage at the GPIO to be less than 0.8V (logic 0) when the transistor is detecting white, and above 2.5V when detecting black. Change the resistance to change the sensitivity. In the case where the phototransistor cannot be used directly, it can drive one input of a comparator while the other input is the reference voltage for detecting white from black, if the comparator is powered from 3.3V it can directly drive the GPIO.</p>

<p>In addition to timing the latency in software, the example code configures GPIO 23 (pin16) as an output so latency can me measured with external hardware or oscilloscope. GPIO 23 is driven high at the start of active video and low again when GPIO 24 goes low, when the phototransistor detects light..</p>

<p><a data-lity="" class="sx-center"><img src="/assets/img/posts/march-2024/scope.png" /></a></p>

<hr />

<h2 id="results">Results</h2>

<p>The black and white test screens aren’t using HVS display lists, only the background color, therefore we can use a display list to display a small buffer in the center of the screen with the results. The displayed result buffer utilizes dark colors to minimize ambient leakage any any affect the phototransistor. The result frame buffer stays away from the corners which are the locations where latency is most likely to be measured. Having the results displayed on the screen being tested makes the tester stand alone as no PC or additional hardware is required.</p>

<h4 id="hdmi">HDMI</h4>

<p>The following test was performed on a Dell U2713HM 27-Inch Monitor receiving 1080P from the following Pi config and the phototransistor in the top left of the screen:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdmi_group=1    #1=CEA, 2=DMT 
hdmi_mode=16    #1080p60
</code></pre></div></div>

<p><a data-lity="" class="sx-center"><img src="/assets/img/posts/march-2024/p1.jpeg" /></a></p>

<p>The result is also output over uart (GPIO 14, pin 8) at 115200 baud, which can be received by a PC for logging.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Elapsed time = 18714 uS
Elapsed time = 18692 uS
Elapsed time = 18734 uS
</code></pre></div></div>

<p>On the same device with the phototransistor placed in the bottom right you see this particular Dell monitor has a display refresh speed of approximately 16.2ms.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Elapsed time = 34825 uS
Elapsed time = 34818 uS
Elapsed time = 34878 uS
</code></pre></div></div>

<p>However the input latency changes with the mode, changing the Pi config to <code class="language-plaintext highlighter-rouge">hdmi_mode=31</code> (1080p 50hz), the input latency at the top right location increases to 28.78ms.</p>

<h4 id="sdtv">SDTV</h4>

<p>The above HDMI tests were on a Dell PC monitor which doesn’t have composite inputs, I switched to a Vizio TV and thought I should retest the HDMI for reference. This particualar TV has almost identical performance to the Dell, about 18ms initial latency and about 16ms draw time. This will be the reference for the SDTV modes.</p>

<p>Setting PAL output with the following config option and remove the hdmi options:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sdtv_mode=2
</code></pre></div></div>

<p>The input latency is a whopping 75ms and the draw time is now 20ms which makes sense for 50hz. I can only assume the TV is waiting for multiple frames to run its de-interlacing algorithm. The 50Hz frame rate is probably not helping because NTSC at 60Hz does have better performance at 55ms but significantly higher than 1080p (which happens to be the panel resolution).</p>

<p><a data-lity="" class="sx-center"><img src="/assets/img/posts/march-2024/p3.jpeg" /></a></p>

<p>This same SDTV test on an old fashioned analog CRT would have latencies that are hard to reliably measure, it would be in single digit microseconds. Putting the SDTV from the latency tester through something like a RetroTink to convert back to HDMI will have much better performance and you can measure the latency of the converter itself.</p>

<hr />

<h2 id="other-pi-hardware">Other PI hardware</h2>

<p>Unfortunately this example code is 64bit bare metal so it will only run on a Pi3. However, there is no reason for it to be 64bit and it only uses a single core. The PV and HVS hardware from the earlier Pi’s is exactly the same. The assembly boot code and utils would need to be rewritten but the C code could simply be re-compiled for 32bit. With 32bit boot code it would be able to run on a PiZero and the total cost of this latency tester would be just a few dollars.</p>

<p>Pi4 and Pi5 still have HVS and PV but they are different. First of all they have more functionality and do things like color correction. Second, there are more units because there are more outputs. Adding support for the Pi4 would enable 4K and HDR output and the associated latency to be measured.</p>

<p>If anybody wants to add this support; feel free to submit a PR.</p>

<hr />

<h2 id="nitty-gritty-timing-details">Nitty Gritty timing details</h2>

<p>When you look closer at the line counter in the HVS stat register, there is a lot more going on than first meets the eye. For example, when outputting 1080p, the line number in the stat register goes from 0 to 1080 which is 1081 total lines… Why??? When does it go to 1080?  When does it go back to zero? Does it stay on zero for longer than it should? What does the HVS do during the vblank? We can try to unravel some of this by simply logging how th various registers change. The code below spins against the current line in the stat register, taking a timestamp when it changes. It first records the data and then prints the results afterwards due to printf() using the UART and being generally slow.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  uint32_t line = hvs[1].dispstat &amp;0xfff;
  uint32_t idx=0;
  uint32_t lines[2048];
  uint32_t times[2048];
  while(idx&lt;2048)
  { 
    uint32_t hw_line = hvs[1].dispstat &amp; 0xfff;
    if (hw_line!=line)
    {
      uint32_t time = Read32(TIMER_LOW);  //0x3f003004
      lines[idx]=hw_line;
      times[idx]=time;
      line=hw_line;
      idx++;
    }
  }

  //the time stamp is taken when we start a new the line so the line time is from the current to the next.
  //Entry 0 might not be a full line, the last entry has no next, so ignore both the ends
  for (uint32_t i=1;i&lt;2047;i++)
  {
    printf("Line %d - time %d [delta %d]\r\n",lines[i],times[i], times[i+1]-times[i]);
  }
</code></pre></div></div>
<p>We get some very interesting results…. Lines in the middle of the frame are really not interesting. Each line take 14 or 15uS which is the scan time of a 1080p line, the bouncing around is due to the timer having microsecond resolution and a 1080p line taking 14.815uS. I think its safe to assume HVS is outputting lines at the same rate they are being consumed by the HDMI encoder.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Line 38 - time 5915378 [delta 14]
Line 39 - time 5915392 [delta 15]
Line 40 - time 5915407 [delta 15]
Line 41 - time 5915422 [delta 15]
Line 42 - time 5915437 [delta 15]
Line 43 - time 5915452 [delta 15]
Line 44 - time 5915467 [delta 14]
Line 45 - time 5915481 [delta 15]
</code></pre></div></div>

<p>Around the end of the frame is where things get really interesting…What is going on between line 1080 and line 7 of the next frame???  After line 7 things go back to outputting one line every 14.815us</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Line 1076 - time 11880867 [delta 16]
Line 1077 - time 11880883 [delta 14]
Line 1078 - time 11880897 [delta 15]
Line 1079 - time 11880912 [delta 14]
Line 1080 - time 11880926 [delta 103]
Line 0 - time 11881029 [delta 3]
Line 2 - time 11881032 [delta 3]
Line 3 - time 11881035 [delta 3]
Line 4 - time 11881038 [delta 3]
Line 6 - time 11881041 [delta 3]
Line 7 - time 11881044 [delta 668]
Line 8 - time 11881712 [delta 14]
Line 9 - time 11881726 [delta 16]                        
Line 10 - time 11881742 [delta 14]
Line 11 - time 11881756 [delta 15]
Line 12 - time 11881771 [delta 15]
Line 13 - time 11881786 [delta 14]
</code></pre></div></div>

<p>These results are incredibly consistent across multiple runs of the same configuration and if we time between line0 on consecutive frames its exactly 16.667mS (this conveniently verifies the accuracy of the micro second timer). Note there are some lines missing, in the above lines 1 and 5 are completely missing! At first I though it was a bug in the code related to loops running slower than expected because the caches are turned off, but the time stamps don’t indicate anytime is missing. The stat register never contained those line numbers and I don’t know why, but I do know if lines take more time generate then they are not skipped by the stat register..</p>

<p>Whatever HVS is doing fits exactly in a frame.. Its also interesting that Line7 takes roughly the same time as the 1080p vblank period.  Lets compare the VFP (Vertical Front Porch) and VACTIVE (visible video) of PV against the line number in HVSe, as expected it occurs during 7 at 1080p and line 18 at 480p. In reality we don’t care what the HSV line is, we’ll simply start the timer as soon as we see vertical active.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  while(1)
  {
    uint32_t stat = pv-&gt;int_status;
    uint32_t hw_line = hvs_channels[1].dispstat &amp; 0xfff;
    if (stat &amp; PV_INTEN_VACT_START)
    {
      pv-&gt;int_status = stat;
      printf("%d\r\n",hw_line);
    }
  }
</code></pre></div></div>
<p>The above code running in 1080p indicates HVS is on line 7, the line that matches the vblank time, when active starts. This does tell us a critical piece of information: We can’t rely on HVS line 0 for the latency tester because this occurs at the end of the previous frame. The line number in HVS is the line it is currently generating and not the line currently being scanned out, and we must use PV to detect the start of active video. While we can detect the area of active scan out by looking at the timeing, we can’t do it reliably for any video mode.</p>

<p>The code below is identical to the code above but waits for Vertical Front Porch, which is also the end of active video from the previous frame…This code will print HVS is on line 0 at VFP….</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  while(1)
  {
    uint32_t stat = pv-&gt;int_status;
    uint32_t hw_line = hvs_channels[1].dispstat &amp; 0xfff;
    if (stat &amp; PV_INTEN_VFP_START)
    {
      pv-&gt;int_status = stat;
      printf("%d\r\n",hw_line);
    }
  }
</code></pre></div></div>

<p>Here is what I believe is happening… HVS starts generating the next frame at the start of the vertical front porch, this gives it the entire vblank period or 667uS, to get a head start. It needs to get a head start because the work load on each scan line isn’t consistent, it depends on what buffers cover which scanlines, how they are blended etc - HVS is basically a big DMA engine.  In the above timing there are no buffers, only the background color, so it should be as fast as possible and HVS generates the first 7 scan lines in 15us.  It appears there is a working FIFO that can hold 7 1080p scan lines, when HVS gets to line 7 it can’t generate it because there is nowhere put it so it has to wait until line 0 has been sent out, which won’t happen until active scan out, therefore it has to wait for the remainder of the vblank and for line 0 to be sent out.   After this one scan line becomes free in the FIFO every time one scan line is sent to the TV encoder, this occurs every 14.815uS, hence why the following lines are spaced at line interval. The actual line only takes HVS 2-3uS to generate but it has to wait because the FIFO is full. What is the time spent at line 1080? I beleive this is how long it takes to empty the FIFO. When the HVS gets to line 1080, it still has 7 lines in the FIFO that need to be scanned out. 7 lines at 14.815uS each is 103.7uS which is how long it was on line 1080..</p>

<p>In the above timing, line7 taking 668 uS which is pretty much the exact length of the vblank in 1080p, is a fluke. Line 7 has to wait for the end the vblank+1 scan line or 14.815us, in this example it just happens to be that the first 7 scanlines also took 15uS.</p>

<p>What happens if we change the display resolution, to say 720x480 with a line period = 31.778uS</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Line 475 - time 87363732 [delta 33]
Line 476 - time 87363765 [delta 31]
Line 477 - time 87363796 [delta 32]
Line 478 - time 87363828 [delta 32]
Line 479 - time 87363860 [delta 31]
Line 480 - time 87363891 [delta 590]
Line 0 - time 87364481 [delta 3] 
Line 3 - time 87364484 [delta 2] 
Line 6 - time 87364486 [delta 3] 
Line 9 - time 87364489 [delta 3] 
Line 12 - time 87364492 [delta 2]
Line 15 - time 87364494 [delta 3]
Line 18 - time 87364497 [delta 1426]
Line 19 - time 87365923 [delta 32]
Line 20 - time 87365955 [delta 32]
Line 21 - time 87365987 [delta 32]
</code></pre></div></div>

<p>You get the same pattern as 1080p but the timing matches the frame timing of 480p. It now blocks until the end of vsync on line 18 and not line 7, this indicates the FIFO is of a certain size in pixels and not a fixed number of lines.. A 1080p frame is 1920 visible pixels/2200 total pixels and the FIFO held 7 lines, a 720x480 is 858 total pixels and the FIFO held 18 lines, the FIFO is something like 16K pixels. Trying other resolitions confirms this.</p>

<p>Whate does HVS do when the output is interlaced?? The timing below is from composite NTSC with 64us lines:</p>

<p>Even field</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Line 570 - time 40490252 [delta 64] [frame 45]
Line 571 - time 40490316 [delta 3] [frame 45]
Line 572 - time 40490319 [delta 61] [frame 45]
Line 573 - time 40490380 [delta 2] [frame 45]
Line 574 - time 40490382 [delta 62] [frame 45]
Line 575 - time 40490444 [delta 2] [frame 45]
</code></pre></div></div>

<p>odd field</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Line 267 - time 40500557 [delta 63] [frame 46]
Line 268 - time 40500620 [delta 3] [frame 46]
Line 269 - time 40500623 [delta 61] [frame 46]
Line 270 - time 40500684 [delta 3] [frame 46]
Line 271 - time 40500687 [delta 61] [frame 46]
Line 272 - time 40500748 [delta 2] [frame 46]
</code></pre></div></div>

<p>HVS processes all the lines but only generates output for the lines needed on the current field, each pair of lines takes 64uS due to filling the FIFO. If you are looking at HVS regsiters an interlaced frame will look very similar to a none interlaced frame.</p>]]></content><author><name>Rob</name></author><category term="[&quot;blog&quot;, &quot;graphics&quot;]" /><summary type="html"><![CDATA[open source SDTV and HDMI latency tester on a Raspberry Pi]]></summary></entry><entry><title type="html">Under the hood of Windows timestamps</title><link href="https://trickybitsblog.github.io/2024/02/25/timestamps.html" rel="alternate" type="text/html" title="Under the hood of Windows timestamps" /><published>2024-02-25T00:00:00-07:00</published><updated>2024-02-25T00:00:00-07:00</updated><id>https://trickybitsblog.github.io/2024/02/25/timestamps</id><content type="html" xml:base="https://trickybitsblog.github.io/2024/02/25/timestamps.html"><![CDATA[<p>Programmers have always needed reliable timestamps and programming on Windows is no different. But getting accurate timestamps efficiently from user mode, a seemingly simple task that every operating system supports, seems to have at best made Microsoft jump through hoops for 30 years, and at worst eluded them completely.</p>

<p>Compared to Linux, where the <code class="language-plaintext highlighter-rouge">clock_gettime</code> API will return all sorts of time stamps to a standardized nanosecond resolution, Windows is not so simple and this leads to assumptions and a quagmire of edge cases. Sure Windows has a complicated legacy and there are lots of backwards compatibility issues that still dictate how time works to this day, buy why is it that even in Windows 11 there not a time API with standard units? Why do we always have to convert from some arbitrary frequency - which only aid assumptions and bad programming? These timing assumptions and other edge cases are typically what cause old software to misbehave when running on modern machines. Old applications sometimes stutter, run too slow, run too fast and sometimes outright crash. These misbehaving apps are not directly Microsoft’s fault, the apps are usually victims of assumptions that were valid at the time.</p>

<p>In this post we are taking a deep dive in to the Windows time APIs to see exactly how they work and how they evolved, from DOS to hypervisors, and we’ll figure out what modern apps should be using and we’ll see that Windows 11 gets pretty close to a standard timer but not quite, but its close enough that it will probably lead to more bad assumptions in the future.</p>

<hr />

<p>For a fleeting moment it seemed like we could avoid all time based APIs and do things ourselves. Starting with the original Pentium processor, some 30 years ago, Intel added the <code class="language-plaintext highlighter-rouge">RDTSC</code> instruction, this reads a hardware time stamp counter (TSC) that incremented every clock cycle, and for the first time applications had a hardware counter that was accessible with low latency in user mode that would provide cycle level precision. For a while all of our timing problems were solved, even a lowly 100Mhz Pentium could give 10ns timestamps, compute accurate elapsed time periods, code could easily be profiled to see the results of the smallest micro optimizations; all things that were exceptionally difficult or impossible with the windows time APIs at the time. However, it didn’t last, while <code class="language-plaintext highlighter-rouge">RDTSC</code> was used all over the place it became very unreliable and a lot of software broke.</p>

<p>Early multiple processor systems had physically different processors in physically different packages and each would have its own none-synchronized TSC. If your code switched processors the <code class="language-plaintext highlighter-rouge">RDTSC</code> instruction could give the impression of time going backwards which causes all sorts of problems. Lots of games and media apps that were written in the days of single processors suffered timing problems due to this. It wasn’t just third party code, even system tools suffered, for example <code class="language-plaintext highlighter-rouge">ping</code> on an early Windows Server sometimes fails with negative time!</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>C:\&gt;ping google.com

Ping google.com (142.250.69.238) with 32 bytes of data:
Reply from 142.250.69.238: bytes=32 time=-59ms TTL=128
Reply from 142.250.69.238: bytes=32 time=-59ms TTL=128
Reply from 142.250.69.238: bytes=32 time=-59ms TTL=128
Reply from 142.250.69.238: bytes=32 time=-59ms TTL=128
</code></pre></div></div>

<p>Over time using <code class="language-plaintext highlighter-rouge">RDTSC</code> on single processors became unreliable because TSC would increment at the raw clock speed of the processor; which wasn’t stable. The frequency would change small amounts due to spread spectrum clocking but would change by huge amounts due to thermal and power management which made TSC unusable. To make things worse, variable frequency clocking happened around the same time as multi-processor machines started to get commonplace so it was a double whammy. <code class="language-plaintext highlighter-rouge">RDTSC</code> could still be used, albeit with great care, but it was generally impossible to correlate the TSC to wall time.  Today this problem is fixed via an invariant TSC which increments at a fixed rate in all power and thermal states, from a software point of view the invariant TSC increments at the base clock speed of the processor, regardless of the actual operating speed. TSC can once again be used for accurate timing as it directly correlates to wall time but Microsoft still recommends to not use the <code class="language-plaintext highlighter-rouge">RDTSC</code> instruction and instead use the <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> API, is this true??? Before we answer that question and dive in to the nitty gritty of <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> along with the role the TSC plays in modern Windows operating systems, lets look at the methods used to get time prior to <code class="language-plaintext highlighter-rouge">RDTSC</code>. There is a lot of history here and its not hard to figure out why <code class="language-plaintext highlighter-rouge">RDTSC</code> got used so much.</p>

<hr />

<p>Prior to <code class="language-plaintext highlighter-rouge">RDTSC</code>, and during the many years that <code class="language-plaintext highlighter-rouge">RDTSC</code> couldn’t reliably be used, Windows only had a few options for elapsed time, most of them were timer interrupt driven, and none of them were great. Stuttering in early games and media was often the result of poor time. <code class="language-plaintext highlighter-rouge">GetTickCount()</code> has been in the Windows API since the 16bit days, it still exists today and is used everywhere. It returns the integer number of milliseconds since the system was booted. The resulting 32bit counter will wrap in 49.7 days and to avoid this modern versions of Windows have <code class="language-plaintext highlighter-rouge">GetTickCount64()</code> which is identical in functionality other than returning a 64bit result. Realistically having a timer wrap in 49.7 days probably wasn’t an issue for Windows3.1 because it wouldn’t stay on that long. While the accuracy of the <code class="language-plaintext highlighter-rouge">GetTickCount()</code> is 1ms, it’s resolution has never been close and still isn’t. Initially the resolution of this API was a whopping 55ms and this was true all the way though the Win9x operating systems, for Windows NT based operating systems the resolution has always been 10-15ms, where it still is today, even on Windows 11.</p>

<p>To understand were the 55ms interval comes from, which seems like a very random number in computer terms, we have to go all the way back to the origins of the PC BIOS. The original IBM PC ran at approximately 4.77MHz, it was clocked at quarter speed by a 1.19318MHz crystal and this also clocked the 8254 programmable interval timer. 65536 cycles at 1.19318MHz is 54.92ms. The timer generated a 18.208Hz interrupt on IRQ8 which was used by the BIOS to track wall time. Early PCs didn’t have a battery backed clock so had no concept of wall time, the user would enter the date and time at boot and the BIOS would keep track of wall time using this interrupt. With 18.208Hz interrupt rate, 2^16 interrupts equals approximately 3599.59 seconds, which is almost exactly one hour. To save a few CPU cycles the BIOS used this almost once an hour 16-bit overflow to check whether the wall time had crossed midnight and when it did, it needed to increment the date.</p>

<p>Lots of DOS games hijacked the 8254 timer hardware and installed their own interrupt handler, so DOS game had access to accurate time. Early Windows ran on top of DOS and used all the DOS and BIOS services as-is, therefore it didn’t mess with the timer hardware. The original <code class="language-plaintext highlighter-rouge">GetTickCount()</code> API was a wrapper for the BIOS timer interrupt, it literally counted interrupts and multiplied that by 54.92 to compute elapsed time in milliseconds. As an optimization, the API did the multiplication only when it was called, amazingly it is still implemented this way on Windows 11 and although the origin of the tick counter is a little different the resolution is still only about 15ms. NT based operating systems were never based on DOS and the NT kernel did hijack the hardware timer. On a single processor NT machine the interrupt period was set to about 10ms, while on a multi processor machines about 15ms; much better than 55ms from 16bit windows and win9x but nowhere near good enough for games and media.</p>

<p>A common pattern within Windows NT based operating systems is to have documented public Win32 APIs that are internally implemented with the somewhat undocumented native API. <code class="language-plaintext highlighter-rouge">GetTickCount</code> was no different, it had been a documented API since the first version of Windows and on Windows NT it simply wrapped the native API <code class="language-plaintext highlighter-rouge">NtGetTickCount</code> which was originally a system call to the kernel.  Therefore getting the elapsed time involved a system call. Today system calls are still expensive and optimizations are in place to avoid them, 30 years ago they were really expensive..</p>

<p>Today, <code class="language-plaintext highlighter-rouge">GetTickCount</code> is just a few instructions, there are no system calls and it doesn’t call <code class="language-plaintext highlighter-rouge">NtGetTickCount</code> (which is implemented identically).</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">GetTickCount:</span>
<span class="nf">mov</span>         <span class="nb">ecx</span><span class="p">,</span><span class="mh">7FFE0320h</span>               <span class="c1">;get the interrupt count</span>
<span class="nf">mov</span>         <span class="nb">rcx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span><span class="p">]</span>         
<span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="mh">7FFE0004h</span><span class="p">]</span>   <span class="c1">;get a 24bit fixed point multiplier (defined by the interrupt period)</span>
<span class="nf">imul</span>        <span class="nb">rax</span><span class="p">,</span><span class="nb">rcx</span>                     <span class="c1">;multiply</span>
<span class="nf">shr</span>         <span class="nb">rax</span><span class="p">,</span><span class="mh">18h</span>                     <span class="c1">;shift down to give integer milliseconds</span>
<span class="nf">ret</span>  
</code></pre></div></div>

<hr />

<p>In the disassembly above it, while it doesn’t use any sycalls, it does read from hardcoded addresses <code class="language-plaintext highlighter-rouge">0x7FFE0320</code> and <code class="language-plaintext highlighter-rouge">0x7FFE0004</code>. These addresses are part of what is known as <code class="language-plaintext highlighter-rouge">kuser_shared</code>, this was first implemented in Windows NT 3.5 and has been there, in some form, ever since. <code class="language-plaintext highlighter-rouge">kuser_shared</code> is a read only memory page mapped to every process by the kernel at fixed address <code class="language-plaintext highlighter-rouge">0x7FFE0000</code>. This allows the kernel to share things like constants, counters and configuration data without having to rely on system calls, user mode code can simply read the data from memory at full speed, and all user mode processes see the same data at the same time. It’s intended for internal use and was never officially documented until <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/ntddk/ns-ntddk-kuser_shared_data">Windows 10 DDK</a>. Needless to say there are a lot of elements in <code class="language-plaintext highlighter-rouge">kuser_shared</code> that relate to time.</p>

<blockquote>
  <p>It’s highly recommended that production code doesn’t poke around in <code class="language-plaintext highlighter-rouge">kuser_shared</code>, it can change between even minor versions of windows; but it’s exactly what we’re going to do.</p>
</blockquote>

<p>Looking back at the disassembly above we can make sense of it. <code class="language-plaintext highlighter-rouge">0x7FFE0320</code> is a 64bit counter, the kernel increments this every tick interrupt. This used to be a 32bit counter at address <code class="language-plaintext highlighter-rouge">0x7FFE0000</code> but that location is no longer used and is zero; a perfect example of why production code shouldn’t use <code class="language-plaintext highlighter-rouge">kuser_shared</code> directly and why some old applications that did no longer work. <code class="language-plaintext highlighter-rouge">0x7FFE004</code> is known as the <code class="language-plaintext highlighter-rouge">TickCountMultiplier</code> and is the interrupt period in units of 100ns, shifted left by 24 bits, and divided by 10,000. Thr conversion of raw tick count to integer milliseconds is simply a multiplication of TickCountMultiplier and a shift right by 24 bits, which is exactly what the above code does (and is pretty much exactly what 16bit windows did).</p>

<p>Today, most machines today have a multiplier of <code class="language-plaintext highlighter-rouge">0x0FA00000</code> which works out to be a period of 156250 (100ns system units) or 15.6250ms. Even in 2024, using Windows 11, the tick interrupt period is 15.625ms and this is the resolution of <code class="language-plaintext highlighter-rouge">GetTickCount</code> - about the same as all the earlier NT based cousins. While the value for the tick count multiplier has been constant at <code class="language-plaintext highlighter-rouge">0x0FA00000</code> for a while, you shouldn’t rely on it and you certainly shouldn’t compute the tick period directly from the multiplier at <code class="language-plaintext highlighter-rouge">0x7FFE0004</code>. There are more legitimate ways to get the tick period from the kernel.</p>

<p>At this point it is worth noting that the tick count at <code class="language-plaintext highlighter-rouge">0x7FFE0320</code>, which drives <code class="language-plaintext highlighter-rouge">GetTickCount</code>, isn’t driven directly from a hardware interrupt like it used to be. Instead, the tick count is abstracted from the more modern kernel interval timer interrupt, which can, and does, change its period on the fly. If I remember from my time on the the Windows kernel, the timer interval interrupt is handled by a function called <code class="language-plaintext highlighter-rouge">KeUpdataSystemTime</code> and in this function the kernel updates the interval interrupt time and then simply decrements the remaining TickCount period with the elapsed time since the last interval interrupt (in 100nS units), when this counter period reaches zero the tick counter at location <code class="language-plaintext highlighter-rouge">0x7FFE0320</code> is incremented - it’s kind crude.  Due to this, the kernel intereval timer interrupt may occur much faster than the tick period but it can never be slower otherwise the tick counter would miss increments.  On my machine the kernel interval interrupt occurs somewhere between 0.5ms and 15.625ms.</p>

<p>Its really important to note that the period of the kernel interval timer interrupt doesn’t have to be a factor of 15.625ms (the tick count speed), in can be anything between the min and max timer period. Therefore, the the tick counter at location <code class="language-plaintext highlighter-rouge">0x7FFE0320</code> might average out to its actual period of 15.625ms, but it has a whole lot of jitter, if the kernel interval timer is set at 7ms, then the kernel might not update the tick count at <code class="language-plaintext highlighter-rouge">0x7FFE0320</code> until 21ms have elapsed.</p>

<blockquote>
  <p>The various counters in <code class="language-plaintext highlighter-rouge">kuser_shared</code> are updated without the need for locks on multi-processor machines. The older 32bit versions of Windows had to jump through a few hoops to ensure the 64bit values were reliably updated.
Everything in this post assumes a modern 64bit version of Windows.</p>
</blockquote>

<p>Here is some test code that show this in real time.  The code spins while it waits for the kernel interval timer interrupt at location <code class="language-plaintext highlighter-rouge">0x7FFE0008</code> to change (this address is the time of the last kernel interval timer interrupt in units of 100ns since boot, its set by the kernel itself within the interrupt handler). The code then looks to see if the tick count has changed and if it has computes the elapsed time from the last update.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="kt">uint64_t</span> <span class="n">old</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="k">volatile</span> <span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="mh">0x7FFE0008</span><span class="p">;</span>
  <span class="kt">uint64_t</span> <span class="n">old_tick</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="k">volatile</span> <span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="mh">0x7FFE0320</span><span class="p">;</span>
  <span class="kt">uint64_t</span> <span class="n">last_tick_change</span> <span class="o">=</span> <span class="n">old</span><span class="p">;</span>
  <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="kt">uint64_t</span> <span class="n">current</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="k">volatile</span> <span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="mh">0x7FFE0008</span><span class="p">;</span>

    <span class="c1">//has a kernel interrupt fired</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">old</span> <span class="o">!=</span> <span class="n">current</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="kt">uint64_t</span> <span class="n">kdelta</span> <span class="o">=</span> <span class="n">current</span> <span class="o">-</span> <span class="n">old</span><span class="p">;</span>
      <span class="kt">uint64_t</span> <span class="n">tick_count</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="k">volatile</span> <span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="mh">0x7FFE0320</span><span class="p">;</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">tick_count</span> <span class="o">==</span> <span class="n">old_tick</span><span class="p">)</span>
      <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"ktimer = %lld (kdelta=%lld), tick=%lld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">current</span><span class="p">,</span> <span class="n">kdelta</span><span class="p">,</span> <span class="n">tick_count</span><span class="p">);</span>
      <span class="p">}</span>
      <span class="k">else</span> 
      <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"ktimer = %lld (kdelta=%lld), tick=%lld, tick_delta=%lld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">current</span><span class="p">,</span> <span class="n">kdelta</span><span class="p">,</span> <span class="n">tick_count</span><span class="p">,</span> <span class="n">current</span> <span class="o">-</span> <span class="n">last_tick_change</span><span class="p">);</span>
        <span class="n">last_tick_change</span> <span class="o">=</span> <span class="n">current</span><span class="p">;</span>
        <span class="n">old_tick</span> <span class="o">=</span> <span class="n">tick_count</span><span class="p">;</span>
      <span class="p">}</span>

      <span class="n">old</span> <span class="o">=</span> <span class="n">current</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Here are real results from my windows 11 test machine, the amount of jitter in tick_delta is not good.</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>initially the timer was running at about 1ms intervals
you can see the tick delta from the previous update is 15.9ms

This 1ms interval continues until it switches to 10ms

ktimer = 4946927507603 (kdelta=9994), tick=31660336, tick_delta=159942
ktimer = 4946927517606 (kdelta=10003), tick=31660336
ktimer = 4946927527603 (kdelta=9997), tick=31660336
ktimer = 4946927537604 (kdelta=10001), tick=31660336
ktimer = 4946927547608 (kdelta=10004), tick=31660336
ktimer = 4946927557606 (kdelta=9998), tick=31660336
ktimer = 4946927567603 (kdelta=9997), tick=31660336
ktimer = 4946927577604 (kdelta=10001), tick=31660336
ktimer = 4946927587604 (kdelta=10000), tick=31660336
ktimer = 4946927597603 (kdelta=9999), tick=31660336
ktimer = 4946927607618 (kdelta=10015), tick=31660336
ktimer = 4946927617607 (kdelta=9989), tick=31660336

Here is where the interrupt interval switches to 10ms, and it because of this
the next tick update doesn't occur until 21ms. 
With a 10ms interval the best the 15.625ms tick can do is bounce between 10 and 20ms

ktimer = 4946927718095 (kdelta=100488), tick=31660337, tick_delta=210492
ktimer = 4946927818092 (kdelta=99997), tick=31660338, tick_delta=99997
ktimer = 4946927918095 (kdelta=100003), tick=31660338
ktimer = 4946928018092 (kdelta=99997), tick=31660339, tick_delta=200000
ktimer = 4946928118084 (kdelta=99992), tick=31660339
ktimer = 4946928218105 (kdelta=100021), tick=31660340, tick_delta=200013
ktimer = 4946928318081 (kdelta=99976), tick=31660341, tick_delta=99976
ktimer = 4946928418096 (kdelta=100015), tick=31660341
ktimer = 4946928518105 (kdelta=100009), tick=31660342, tick_delta=200024
ktimer = 4946928618088 (kdelta=99983), tick=31660343, tick_delta=99983
ktimer = 4946928718076 (kdelta=99988), tick=31660343
ktimer = 4946928818082 (kdelta=100006), tick=31660344, tick_delta=199994

from here the interval is quite random for a while

ktimer = 4946928848076 (kdelta=29994), tick=31660344
ktimer = 4946928858169 (kdelta=10093), tick=31660344
ktimer = 4946928867110 (kdelta=8941), tick=31660344
ktimer = 4946928868757 (kdelta=1647), tick=31660344
ktimer = 4946928869416 (kdelta=659), tick=31660344
ktimer = 4946928947830 (kdelta=78414), tick=31660345, tick_delta=129748
ktimer = 4946928948959 (kdelta=1129), tick=31660345
ktimer = 4946928958946 (kdelta=9987), tick=31660345
ktimer = 4946928967940 (kdelta=8994), tick=31660345
ktimer = 4946929063042 (kdelta=95102), tick=31660346, tick_delta=115212
</code></pre></div></div>

<p>You don’t have to compute the elapsed time between 2 timer interrupts to work out the current speed of the kernel interval timer, we can use native api function <code class="language-plaintext highlighter-rouge">NtQueryTimerResolution</code>, this fills out the minimum resolution (slowest timer rate), the maximum resolution (fastest timer rate), and the current resolution at the time it was called (all in 100ns system time units). The minimum resolution for the kernel interval timer will always be the the tick count interval, this ensures the tick counter always increments monotonically and never misses a value.</p>

<blockquote>
  <p>There are no easily accessible headers for the native API. You have to declare the functions yourself and either link with static library ntdll.lib, or use <code class="language-plaintext highlighter-rouge">GetProcAddress</code> on ntdll.dll to dynamically link.</p>
</blockquote>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">extern</span> <span class="s">"C"</span> <span class="n">NTSYSAPI</span> <span class="n">NTSTATUS</span> <span class="n">NTAPI</span> <span class="nf">NtQueryTimerResolution</span><span class="p">(</span>
  <span class="n">OUT</span> <span class="n">PULONG</span> <span class="n">MinimumResolution</span><span class="p">,</span>
  <span class="n">OUT</span> <span class="n">PULONG</span> <span class="n">MaximumResolution</span><span class="p">,</span> 
  <span class="n">OUT</span> <span class="n">PULONG</span> <span class="n">CurrentResolution</span><span class="p">);</span>


  <span class="c1">//get the min, max and current resolution</span>
  <span class="n">ULONG</span> <span class="n">minRes</span><span class="p">;</span>
  <span class="n">ULONG</span> <span class="n">maxRes</span><span class="p">;</span>
  <span class="n">ULONG</span> <span class="n">currentRes</span><span class="p">;</span>
  <span class="n">NtQueryTimerResolution</span><span class="p">(</span><span class="o">&amp;</span><span class="n">minRes</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">maxRes</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">currentRes</span><span class="p">);</span>
</code></pre></div></div>

<p>On my machine <code class="language-plaintext highlighter-rouge">NtQueryTimerResolution</code> reports a minimum period (maximum resolution) of 5000 or 0.5ms and a maximum period (minimum resolution) of 156250 or 15.625ms. Calling this in a loop and displaying the current resolution will should the kernel timer changing resolution on the fly.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kernel timer resolution = 156250
kernel timer resolution = 100000
kernel timer resolution = 156250
kernel timer resolution = 10000
kernel timer resolution = 10000
kernel timer resolution = 10000
kernel timer resolution = 156250
</code></pre></div></div>

<p>The reason is the kernel timer resolution changes is because it’s a system wide setting. The default value is the minimum resolution (15.625ms) but it will change as other processes ask for a different resolution, the final resolution will always be set to the minimum interval that has been asked for by any process - this is not a bad random seed because it depends entirely on the processes that are running and what they are currently doing. In both of the above time logs it is easy to see that periodically some process is asking for 1ms resolution, which is common due to how the newer multimedia timers work, but in order to satisfy such a request, everybody gets 1ms resolution.</p>

<p>The timer resolution can be set directly using native API <code class="language-plaintext highlighter-rouge">NtSetTimerResolution</code>:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">extern</span> <span class="s">"C"</span> <span class="n">NTSYSAPI</span> <span class="n">NTSTATUS</span> <span class="n">NTAPI</span> <span class="nf">NtSetTimerResolution</span><span class="p">(</span><span class="n">ULONG</span> <span class="n">DesiredResolution</span><span class="p">,</span> <span class="n">BOOLEAN</span> <span class="n">SetResolution</span><span class="p">,</span> <span class="n">PULONG</span> <span class="n">CurrentResolution</span><span class="p">);</span>

<span class="c1">//currentRes will be set to the current resolution, it may not be what you asked for if some other process has asked for a higher resolution. </span>
<span class="n">ULONG</span> <span class="n">currentRes</span><span class="p">;</span>
<span class="n">NtSetTimerResolution</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">TRUE</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">currentRes</span><span class="p">);</span>
</code></pre></div></div>

<p>The resolution has to be between the min and max reported by <code class="language-plaintext highlighter-rouge">NtQueryTimerResolution</code> and it returns the current set resolution, which may not be what you asked because some other process may have already set it to a higher resolution. If we always set the maximum resolution, then the timer rate should be constant because no other process will be able to change it.  Including a call to <code class="language-plaintext highlighter-rouge">NtSetTimerResolution</code> and running the same log again we get much cleaner results, the kernel timer fires every 5000 time units (0.5ms) and the jitter across the tick counter is much more consistent.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ktimer = 4948512812590 (kdelta=5001), tick=31670482, tick_delta=155002
ktimer = 4948512817589 (kdelta=4999), tick=31670482
ktimer = 4948512822590 (kdelta=5001), tick=31670482
ktimer = 4948512827590 (kdelta=5000), tick=31670482
ktimer = 4948512832590 (kdelta=5000), tick=31670482
ktimer = 4948512837589 (kdelta=4999), tick=31670482
ktimer = 4948512842590 (kdelta=5001), tick=31670482
ktimer = 4948512847589 (kdelta=4999), tick=31670482
ktimer = 4948512852589 (kdelta=5000), tick=31670482
ktimer = 4948512857593 (kdelta=5004), tick=31670482
ktimer = 4948512862590 (kdelta=4997), tick=31670482
ktimer = 4948512867595 (kdelta=5005), tick=31670482
ktimer = 4948512872589 (kdelta=4994), tick=31670482
ktimer = 4948512877588 (kdelta=4999), tick=31670482
ktimer = 4948512882589 (kdelta=5001), tick=31670482
ktimer = 4948512887589 (kdelta=5000), tick=31670482
ktimer = 4948512892589 (kdelta=5000), tick=31670482
ktimer = 4948512897589 (kdelta=5000), tick=31670482
ktimer = 4948512902600 (kdelta=5011), tick=31670482
ktimer = 4948512907592 (kdelta=4992), tick=31670482
ktimer = 4948512912590 (kdelta=4998), tick=31670482
ktimer = 4948512917606 (kdelta=5016), tick=31670482
ktimer = 4948512922597 (kdelta=4991), tick=31670482
ktimer = 4948512927605 (kdelta=5008), tick=31670482
ktimer = 4948512932591 (kdelta=4986), tick=31670482
ktimer = 4948512937591 (kdelta=5000), tick=31670482
ktimer = 4948512942592 (kdelta=5001), tick=31670482
ktimer = 4948512947589 (kdelta=4997), tick=31670482
ktimer = 4948512952589 (kdelta=5000), tick=31670482
ktimer = 4948512957616 (kdelta=5027), tick=31670482
ktimer = 4948512962590 (kdelta=4974), tick=31670482
ktimer = 4948512967589 (kdelta=4999), tick=31670482
ktimer = 4948512972589 (kdelta=5000), tick=31670483, tick_delta=159999
</code></pre></div></div>

<p>Unfortunately the windows kernel makes no effort to minimize timer jitter, it doesn’t try to compute a common factor of the requested periods, it simply uses the minimum period, if you need low jitter the only option is to set the kernel timer to the maximum available resolution. The downside of this is using 0.5ms intervals generates 2000 kernel interrupts per second, while that sounds bad it doesn’t really have any noticeable effect on performance, Microsoft should just use a fixed the interval and be done with it.</p>

<p>In the above code another useful value from <code class="language-plaintext highlighter-rouge">0x7FFE0008</code> in <code class="language-plaintext highlighter-rouge">kuser_shared</code> was used, this is the last kernel interrupt time in 100ns system units. Reading the last interrupt time is a much better way to measure elapsed time than GetTickCount(), its higher resolution and more accurate. One way to get the last kernel timer interrupt time is to directly read <code class="language-plaintext highlighter-rouge">0x7FFE0008</code>, the best way is to use <code class="language-plaintext highlighter-rouge">QueryInterruptTime()</code> which does exactly the same:</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">QueryInterruptTime:</span>
  <span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="mh">7FFE0008h</span>  
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rax</span><span class="p">]</span>  
  <span class="nf">mov</span>         <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span><span class="p">],</span><span class="nb">rax</span>  
  <span class="nf">ret</span>  
</code></pre></div></div>

<p>Windows 95 added the <code class="language-plaintext highlighter-rouge">timeGetTime</code> API as part of the multimedia APIs, the same APIs first showed up on NT based operating systems in Windows2000. These new APIs were still only accurate to integer milliseconds but apps could get 1ms resolution too. These APIs still weren’t great for accurately measuring elapsed time or scheduling video frames but given the lack of better options both games and multimedia apps used these extensively, even today these APIs are still used everywhere. Applications used <code class="language-plaintext highlighter-rouge">timeBeginPeriod</code> to set the resolution of the timer, as you can probably guess, this is just wrapper for <code class="language-plaintext highlighter-rouge">NtSetTimerResolution</code> with input quantized to whole milliseconds, with 1ms being the minimum. This is why 1ms shows up quite often in the above timer resolution log.</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">timeGetTime:</span>
  <span class="nf">sub</span>         <span class="nb">rsp</span><span class="p">,</span><span class="mh">28h</span>  
  <span class="nf">xor</span>         <span class="nb">r9d</span><span class="p">,</span><span class="nb">r9d</span>  
  <span class="nf">lea</span>         <span class="nb">rdx</span><span class="p">,[</span><span class="nv">TimeInit</span><span class="p">]</span>  
  <span class="nf">xor</span>         <span class="nb">r8d</span><span class="p">,</span><span class="nb">r8d</span>  
  <span class="nf">lea</span>         <span class="nb">rcx</span><span class="p">,[</span><span class="nv">g_TimeInitOnce</span><span class="p">]</span>  
  <span class="nf">call</span>        <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">__imp_InitOnceExecuteOnce</span><span class="p">]</span>   <span class="c1">;Only run the init code once, from any thread within a given process</span>
  <span class="nf">nop</span>         <span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rax</span><span class="o">+</span><span class="nb">rax</span><span class="p">]</span>  
  <span class="nf">mov</span>         <span class="nb">ecx</span><span class="p">,</span><span class="mh">7FFE0008h</span>                           <span class="c1">;last interrupt time</span>
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="mh">346DC5D63886594Bh</span>                   <span class="c1">;fixed point multiply by 1/100000</span>
  <span class="nf">mov</span>         <span class="nb">rcx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span><span class="p">]</span>  
  <span class="nf">sub</span>         <span class="nb">rcx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">TimerData</span><span class="p">]</span>               <span class="c1">;subtract raw init time from TimerData  </span>
  <span class="nf">imul</span>        <span class="nb">rcx</span>  
  <span class="nf">sar</span>         <span class="nb">rdx</span><span class="p">,</span><span class="mh">0Bh</span>  
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="nb">rdx</span>  
  <span class="nf">shr</span>         <span class="nb">rax</span><span class="p">,</span><span class="mh">3Fh</span>  
  <span class="nf">add</span>         <span class="nb">rax</span><span class="p">,</span><span class="nb">rdx</span>  
  <span class="nf">add</span>         <span class="nb">eax</span><span class="p">,</span><span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">TimerData</span><span class="o">+</span><span class="mh">8h</span><span class="p">]</span>            <span class="c1">;add on the init time in ms from TimerData+8 </span>
  <span class="nf">add</span>         <span class="nb">rsp</span><span class="p">,</span><span class="mh">28h</span>  
  <span class="nf">ret</span>  
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">timeGetTime</code> just returns a scaled and offset version of the 64bit interrupt time. The multimedia timers are significantly better than <code class="language-plaintext highlighter-rouge">GetTickCount</code> but there is no point in using them in new code as there is far less cpu overhead by calling <code class="language-plaintext highlighter-rouge">QueryInterruptTime</code> and you get 100ns accuracy (you are still at the whim of the kernel timer interrupt interval if you don’t set it yourself).</p>

<p>Using <code class="language-plaintext highlighter-rouge">QueryInterruptTime</code> after setting the timer resolution to 0.5ms:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="kt">uint64_t</span> <span class="n">old_tick</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="kt">uint64_t</span> <span class="n">tick</span><span class="p">;</span>
    <span class="n">QueryInterruptTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tick</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">tick</span> <span class="o">!=</span> <span class="n">old_tick</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="kt">double</span> <span class="n">delta</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span><span class="p">)(</span><span class="n">tick</span> <span class="o">-</span> <span class="n">old_tick</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10000.0</span><span class="p">;</span>
      <span class="n">printf</span><span class="p">(</span><span class="s">"delta = %0.6f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">delta</span><span class="p">);</span>
      <span class="n">old_tick</span> <span class="o">=</span> <span class="n">tick</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The result is quite stable, the interrupt time is within a few microseconds of the expected time, but half a millisecond is the smallest interval that can be measured and this still can’t accurately measure a 16.6ms frame time.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>delta = 0.500100
delta = 0.502400
delta = 0.497900
delta = 0.499500
delta = 0.500200
delta = 0.500200
delta = 0.499800
delta = 0.500400
delta = 0.499600
delta = 0.500100
delta = 0.499900
delta = 0.499900
delta = 0.500500
</code></pre></div></div>

<p>Windows also provides an API called <code class="language-plaintext highlighter-rouge">GetSystemTimeAsFileTime</code> which returns the system current time as a file time. Within Windows, system time and file time are both in units of 100ns, system time is the elapsed time since boot while file time is the elapsed time since the epoch (Jan 1st 1601). However this API is also driven by the same timer interrupt timestamp but instead of reading <code class="language-plaintext highlighter-rouge">0x7FFE0008</code> which is the system timestamp, it reads <code class="language-plaintext highlighter-rouge">0x7FFE0014</code> which is the file time timestamp of the last timer interrupt.</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">; This API splits the 64bit result in to a pair of 32bit values instead of directly returning a 64bit value. </span>
<span class="nl">GetSystemTimeAsFileTime:</span>
  <span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="mh">7FFE0014h</span>  
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rax</span><span class="p">]</span>  
  <span class="nf">mov</span>         <span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span><span class="p">],</span><span class="nb">eax</span>  
  <span class="nf">shr</span>         <span class="nb">rax</span><span class="p">,</span><span class="mh">20h</span>  
  <span class="nf">mov</span>         <span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span><span class="o">+</span><span class="mi">4</span><span class="p">],</span><span class="nb">eax</span>  
  <span class="nf">ret</span>  
</code></pre></div></div>

<p>There is a precise version of this API called <code class="language-plaintext highlighter-rouge">GetSystemTimePreciseAsFileTime</code> which is a wrapper for the native function <code class="language-plaintext highlighter-rouge">rtlGetSystemTimePrecise</code> and internally it uses native function <code class="language-plaintext highlighter-rouge">rtlQueryPerformanceCounter</code> along the last interrupt time and some other magic values within kuser_shared, ultimately it returns the file time of when the API was actually called.</p>

<blockquote>
  <p>This function uses address <code class="language-plaintext highlighter-rouge">0x7FFE0340</code> which is the incrementing tick count of the kernel timer interrupt. This counter is shifted left one bit so it appears to increment by 2, and the bottom bit is a lock bit. It’s very difficult to catch the lock bit set but I believe it is set while the kernel interrupt executes to indicate the timer values are changing. There are a lot of timer related values within <code class="language-plaintext highlighter-rouge">kuser_shared</code> and they can’t all be updated atomically, especially from a multi-processor point of view. You’ll see this value being used in the following code:</p>
</blockquote>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">RtlGetSystemTimePrecise:</span>
  <span class="nf">mov</span>         <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">10h</span><span class="p">],</span><span class="nb">rbx</span>  
  <span class="nf">mov</span>         <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">18h</span><span class="p">],</span><span class="nb">rbp</span>  
  <span class="nf">mov</span>         <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">20h</span><span class="p">],</span><span class="nb">rsi</span>  
  <span class="nf">push</span>        <span class="nb">rdi</span>  
  <span class="nf">push</span>        <span class="nv">r12</span>  
  <span class="nf">push</span>        <span class="nv">r13</span>  
  <span class="nf">push</span>        <span class="nv">r14</span>  
  <span class="nf">push</span>        <span class="nv">r15</span>  
  <span class="nf">sub</span>         <span class="nb">rsp</span><span class="p">,</span><span class="mh">20h</span>  
  <span class="nf">mov</span>         <span class="nb">edi</span><span class="p">,</span><span class="mh">7FFE0358h</span>         
  <span class="nf">lea</span>         <span class="nb">r12d</span><span class="p">,[</span><span class="nb">rdi</span><span class="o">-</span><span class="mh">18h</span><span class="p">]</span>  
  <span class="nf">lea</span>         <span class="nb">r13d</span><span class="p">,[</span><span class="nb">rdi</span><span class="o">-</span><span class="mh">10h</span><span class="p">]</span>
<span class="nl">retry2:</span>  
  <span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="mh">7FFE0368h</span>  
  <span class="nf">mov</span>         <span class="nb">ecx</span><span class="p">,</span><span class="mh">7FFE0014h</span>
<span class="nl">retry1:</span>  
  <span class="nf">mov</span>         <span class="nb">rbx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r12</span><span class="p">]</span>                              <span class="c1">;0x340 - kernel timer counter + lock</span>
  <span class="nf">test</span>        <span class="nb">bl</span><span class="p">,</span><span class="mi">1</span>  
  <span class="nf">jne</span>         <span class="nv">pause1</span>                                           <span class="c1">;if the lock in the bottom bit of 0x340 is set, pause and try again (aka locked)</span>
  <span class="nf">mov</span>         <span class="nv">r14</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span><span class="p">]</span>                              <span class="c1">;load system time for last interrupt  </span>
  <span class="nf">lea</span>         <span class="nb">rcx</span><span class="p">,[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">50h</span><span class="p">]</span>                                    <span class="c1">;result location of RtlQueryPerformanceCounter</span>
  <span class="nf">mov</span>         <span class="nb">rbp</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r13</span><span class="p">]</span>                              <span class="c1">;baseline qpc interrupt time</span>
  <span class="nf">mov</span>         <span class="nv">r15</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rdi</span><span class="p">]</span>                              <span class="c1">;qpc system time increment</span>
  <span class="nf">mov</span>         <span class="nb">si</span><span class="nv">l</span><span class="p">,</span><span class="kt">byte</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rax</span><span class="p">]</span>                               <span class="c1">;time shift</span>
  <span class="nf">call</span>        <span class="nv">RtlQueryPerformanceCounter</span>                       <span class="c1">;get the qpc time stamp</span>
  <span class="nf">nop</span>  
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r12</span><span class="p">]</span>                              <span class="c1">;reload the interrupt counter/lock from 0x340</span>
  <span class="nf">cmp</span>         <span class="nb">rax</span><span class="p">,</span><span class="nb">rbx</span>  
  <span class="nf">jne</span>         <span class="nv">pause2</span>                                           <span class="c1">;if a timer interrupt has occurred or the lock has changed, spin and try again  </span>
  <span class="nf">mov</span>         <span class="nb">rdx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">50h</span><span class="p">]</span>                          <span class="c1">;result of RtlQueryPerformanceCounter</span>
  <span class="nf">mov</span>         <span class="nb">edi</span><span class="p">,</span><span class="mi">0</span>                                            <span class="c1">;delta time from last interrupt</span>
  <span class="nf">cmp</span>         <span class="nb">rdx</span><span class="p">,</span><span class="nb">rbp</span>                                          <span class="c1">;current qpc vs qpc interrupt time  </span>
  <span class="nf">jbe</span>         <span class="nv">comp_result</span>                                      <span class="c1">;qpc is below or equal (shouldn't happen), delta is zero, return the last interrupt</span>
  <span class="nf">sub</span>         <span class="nb">rdx</span><span class="p">,</span><span class="nb">rbp</span>                                          <span class="c1">;qpc delta since last interrupt		</span>
  <span class="nf">dec</span>         <span class="nb">rdx</span>	                                   
  <span class="nf">test</span>        <span class="nb">si</span><span class="nv">l</span><span class="p">,</span><span class="nb">si</span><span class="nv">l</span>  
  <span class="nf">je</span>          <span class="nv">skip_shift</span>                                       <span class="c1">;if shift is zero, skip shifting</span>
  <span class="nf">mov</span>         <span class="nb">cl</span><span class="p">,</span><span class="nb">si</span><span class="nv">l</span>  
  <span class="nf">shl</span>         <span class="nb">rdx</span><span class="p">,</span><span class="nb">cl</span>                                           <span class="c1">;shift qpc delta by the shift amount</span>
<span class="nl">skip_shift:</span>
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="nv">r15</span>                                          <span class="c1">;qpc system time increment  </span>
  <span class="nf">mul</span>         <span class="nb">rax</span><span class="p">,</span><span class="nb">rdx</span>                                          <span class="c1">;multiply the time delta by the time increment to compute 100ns  </span>
  <span class="nf">mov</span>         <span class="nb">rdi</span><span class="p">,</span><span class="nb">rdx</span>  
  <span class="nf">mov</span>         <span class="nb">rbx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">58h</span><span class="p">]</span>  
<span class="nl">comp_result:</span>
  <span class="nf">lea</span>         <span class="nb">rax</span><span class="p">,[</span><span class="nv">r14</span><span class="o">+</span><span class="nb">rdi</span><span class="p">]</span>                                    <span class="c1">;add 100ns unit delta time to the baseline interrupt time in 100ns</span>
  <span class="nf">mov</span>         <span class="nb">rbp</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">60h</span><span class="p">]</span>  
  <span class="nf">mov</span>         <span class="nb">rsi</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">68h</span><span class="p">]</span>  
  <span class="nf">add</span>         <span class="nb">rsp</span><span class="p">,</span><span class="mh">20h</span>  
  <span class="nf">pop</span>         <span class="nv">r15</span>  
  <span class="nf">pop</span>         <span class="nv">r14</span>  
  <span class="nf">pop</span>         <span class="nv">r13</span>  
  <span class="nf">pop</span>         <span class="nv">r12</span>  
  <span class="nf">pop</span>         <span class="nb">rdi</span>  
  <span class="nf">ret</span>  
  <span class="nf">int</span>         <span class="mi">3</span>  
<span class="nl">pause1:</span>
  <span class="nf">pause</span>  
  <span class="nf">jmp</span>         <span class="nv">retry1</span>   
<span class="nl">pause2:</span>
  <span class="nf">pause</span>  
  <span class="nf">jmp</span>         <span class="nv">retry2</span>
</code></pre></div></div>

<p>This is the first API that takes us away from times based on the kernel timer interrupt to a now time of when the API was actually called, its the first API to eliminate the kernel timer jitter and the first API that can be correlated to wall time. The implementation of <code class="language-plaintext highlighter-rouge">RtlGetSystemTimePrecise</code> jumps through some hoops because it always returns time in 100ns units and although it uses <code class="language-plaintext highlighter-rouge">rtlQueryPerformanceCounter</code> it has to do a scale and offset because <code class="language-plaintext highlighter-rouge">rtlQueryPerformanceCounter</code> doesn’t have a fixed frequency.</p>

<blockquote>
  <p>Following the typical NT native API pattern, the user api <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> and <code class="language-plaintext highlighter-rouge">rtlQueryPerformanceCounter</code> are the same thing.</p>
</blockquote>

<p>Windows NT system and file times have always been in 100ns units so it would make sense that <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> would return the same 100ns units but for some reason this took until windows 10 build 1607 (Anniversary update in 2016). Today, it is mostly true that the frequency of <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> has been fixed at 10Mhz but its not guaranteed, make assumptions at your own risk.  Over the years <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> has used a range of frequencies depending on the source timer but it will always have resolution greater than 1us.</p>

<p>The frequency of <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> can be obtained via <code class="language-plaintext highlighter-rouge">QueryPerformanceFrequency</code> and all this does is load and return the 64bit value at <code class="language-plaintext highlighter-rouge">0x7FEE0300</code> which is set by the kernel once at boot and never changes at runtime.</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">QueryPerformanceFrequency:</span>
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="mh">7FFE0300h</span><span class="p">]</span>  
  <span class="nf">mov</span>         <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span><span class="p">],</span><span class="nb">rax</span>  
  <span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="mi">1</span>  
  <span class="nf">ret</span> 
</code></pre></div></div>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> and <code class="language-plaintext highlighter-rouge">rtlQueryPerformanceCounter</code> have a native equivalent called <code class="language-plaintext highlighter-rouge">NtQueryPerformanceCounter</code>. The big difference is that <code class="language-plaintext highlighter-rouge">NtQueryPerformanceCounter</code> is <em>always</em> a syscall to the kernel, even though it computes the exact same result.</p>
</blockquote>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">QueryPerformanceCounter:</span>
  <span class="nf">mov</span>         <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mi">8</span><span class="p">],</span><span class="nb">rbx</span>  
  <span class="nf">push</span>        <span class="nb">rdi</span>  
  <span class="nf">sub</span>         <span class="nb">rsp</span><span class="p">,</span><span class="mh">20h</span>  
  <span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="mh">7FFE03C6h</span>                     <span class="c1">;qpc flags address</span>
  <span class="nf">mov</span>         <span class="nb">rbx</span><span class="p">,</span><span class="nb">rcx</span>  
  <span class="nf">movzx</span>       <span class="nb">r9d</span><span class="p">,</span><span class="kt">byte</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rax</span><span class="p">]</span>                <span class="c1">;load qpc flags</span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="mi">1</span>                             <span class="c1">;check bypass syscall  </span>
  <span class="nf">je</span>          <span class="nv">use_syscall</span>                       <span class="c1">;NtQueryPerformanceCounter (syscall 31h)</span>
  <span class="nf">mov</span>         <span class="nb">r11d</span><span class="p">,</span><span class="mh">7FFE03B8h</span>                    <span class="c1">;qpc bias address</span>
  <span class="nf">mov</span>         <span class="nv">r11</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r11</span><span class="p">]</span>               <span class="c1">;load qpc bias </span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="mi">2</span>                             <span class="c1">;check qpc flags for using hypervisor page</span>
  <span class="nf">je</span>          <span class="nv">no_hyperv</span>                         <span class="c1">;no hypervisor page</span>

  <span class="nf">mov</span>         <span class="nv">r8</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="mh">7FFBB84332A8h</span><span class="p">]</span>      <span class="c1">;RtlpHypervisorSharedUserVa = 000000007FFE1000</span>
  <span class="nf">test</span>        <span class="nv">r8</span><span class="p">,</span><span class="nv">r8</span>                             <span class="c1">;is the hypervisor page null??</span>
  <span class="nf">je</span>          <span class="nv">use_syscall</span>                       <span class="c1">;if null, use syscall</span>
<span class="nl">loop_hyperv:</span>
  <span class="nf">mov</span>         <span class="nb">r10d</span><span class="p">,</span><span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r8</span><span class="p">]</span>               <span class="c1">;load cookie from RtlpHypervisorSharedUserVa+0</span>
  <span class="nf">test</span>        <span class="nb">r10d</span><span class="p">,</span><span class="nb">r10d</span>                         <span class="c1">;is the cookie zero?</span>
  <span class="nf">je</span>          <span class="nv">use_syscall</span>                       <span class="c1">;if cookie is zero use syscall</span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="nb">r9b</span>                           <span class="c1">;is rdtscp available? </span>
  <span class="nf">jns</span>         <span class="nv">use_rdtsc_hyperv</span>                  <span class="c1">;if no use rdtsc and some combo of lfence/mfence</span>
  <span class="nf">rdtscp</span>  
<span class="nl">rdtsc_result_hyperv:</span>
  <span class="nf">shl</span>         <span class="nb">rdx</span><span class="p">,</span><span class="mh">20h</span>  
  <span class="nf">or</span>          <span class="nb">rdx</span><span class="p">,</span><span class="nb">rax</span>                           <span class="c1">;make 64bit result from rdtsc  </span>
  <span class="nf">mov</span>         <span class="nb">rax</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r8</span><span class="o">+</span><span class="mi">8</span><span class="p">]</span>              <span class="c1">;load scale at RtlpHypervisorSharedUserVa+8  </span>
  <span class="nf">mov</span>         <span class="nb">rcx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r8</span><span class="o">+</span><span class="mh">10h</span><span class="p">]</span>            <span class="c1">;load offset at RtlpHypervisorSharedUserVa+16</span>
  <span class="nf">mul</span>         <span class="nb">rax</span><span class="p">,</span><span class="nb">rdx</span>                           <span class="c1">;multiply by scale</span>
  <span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nv">r8</span><span class="p">]</span>                <span class="c1">;reload cookie from RtlpHypervisorSharedUserVa+0</span>
  <span class="nf">add</span>         <span class="nb">rdx</span><span class="p">,</span><span class="nb">rcx</span>                           <span class="c1">;add the offset</span>
  <span class="nf">cmp</span>         <span class="nb">eax</span><span class="p">,</span><span class="nb">r10d</span>                
  <span class="nf">jne</span>         <span class="nv">loop_hyperv</span>                       <span class="c1">;do again if hypervisor cookie as changed, maybe the scale/offset changed.</span>

<span class="nl">compute_result:</span>
  <span class="nf">mov</span>         <span class="nb">cl</span><span class="p">,</span><span class="kt">byte</span> <span class="nv">ptr</span> <span class="p">[</span><span class="mh">7FFE03C7h</span><span class="p">]</span>           <span class="c1">;load qpc shift</span>
  <span class="nf">lea</span>         <span class="nb">rax</span><span class="p">,[</span><span class="nb">rdx</span><span class="o">+</span><span class="nv">r11</span><span class="p">]</span>                     <span class="c1">;add on qpc bias</span>
  <span class="nf">shr</span>         <span class="nb">rax</span><span class="p">,</span><span class="nb">cl</span>                            <span class="c1">;shift the result right</span>
  <span class="nf">mov</span>         <span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rbx</span><span class="p">],</span><span class="nb">rax</span>               <span class="c1">;store result  </span>
  <span class="nf">mov</span>         <span class="nb">eax</span><span class="p">,</span><span class="mi">1</span>                             <span class="c1">;return true</span>
  <span class="nf">mov</span>         <span class="nb">rbx</span><span class="p">,</span><span class="kt">qword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span><span class="o">+</span><span class="mh">30h</span><span class="p">]</span>  
  <span class="nf">add</span>         <span class="nb">rsp</span><span class="p">,</span><span class="mh">20h</span>  
  <span class="nf">pop</span>         <span class="nb">rdi</span>  
  <span class="nf">ret</span>  

<span class="c1">;main code path if the hypervisor isn't being used</span>
<span class="nl">no_hyperv:</span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="nb">r9b</span>                       <span class="c1">;is rdtscp available</span>
  <span class="nf">jns</span>         <span class="nv">use_rdtsc</span>                     <span class="c1">;if not, use rdtsc</span>
  <span class="nf">rdtscp</span> 
<span class="nl">rdtsc_result:</span>                               <span class="c1">;if using rdtsc, it returns here</span>
  <span class="nf">shl</span>         <span class="nb">rdx</span><span class="p">,</span><span class="mh">20h</span>  
  <span class="nf">or</span>          <span class="nb">rdx</span><span class="p">,</span><span class="nb">rax</span>                       <span class="c1">;make 64bit value </span>
  <span class="nf">jmp</span>         <span class="nv">compute_result</span>                <span class="c1">;compute final result and return</span>

<span class="c1">;this is the hypervisor rdtsc path, identical to below, we just check sync flags prior to rdtsc</span>
<span class="nl">use_rdtsc_hyperv:</span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="mh">20h</span>                       <span class="c1">;use lfence?</span>
  <span class="nf">je</span>          <span class="nv">no_lfence_hyperv</span>  
  <span class="nf">lfence</span>  
  <span class="nf">jmp</span>         <span class="nv">read_tsc_hyperv</span>  
<span class="nl">no_lfence_hyperv:</span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="mh">10h</span>                       <span class="c1">;use mfence?</span>
  <span class="nf">je</span>          <span class="nv">read_tsc_hyperv</span>  
  <span class="nf">mfence</span>  
<span class="nl">read_tsc_hyperv:</span>
  <span class="nf">rdtsc</span>  
  <span class="nf">jmp</span>         <span class="nv">rdtsc_result_hyperv</span> 

<span class="c1">;this is none hypervisor rdtsc, we might need a sync instruction before the rdtsc</span>
<span class="nl">use_rdtsc:</span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="mh">20h</span>                       <span class="c1">;use lfence for sync</span>
  <span class="nf">je</span>          <span class="nv">skip_lfence</span>  
  <span class="nf">lfence</span>  
  <span class="nf">jmp</span>         <span class="nv">read_tsc</span>
<span class="nl">skip_lfence:</span>
  <span class="nf">test</span>        <span class="nb">r9b</span><span class="p">,</span><span class="mh">10h</span>                       <span class="c1">;use mfence for sync</span>
  <span class="nf">je</span>          <span class="nv">read_tsc</span>  
  <span class="nf">mfence</span>
<span class="nl">read_tsc:</span>  
  <span class="nf">rdtsc</span>  
  <span class="nf">jmp</span>         <span class="nv">rdtsc_result</span>  
<span class="nl">use_syscall:</span>
  <span class="nf">....</span>                
</code></pre></div></div>

<p>Dissecting the above code there are a few different paths but ultimately only 2 modes of operation. It’s either a syscall or some derivative of the TSC read with either <code class="language-plaintext highlighter-rouge">RDTSC</code> or <code class="language-plaintext highlighter-rouge">RDTSCP</code>. The difference between these two almost identical instructions is the original <code class="language-plaintext highlighter-rouge">RDTSC</code> is a speculative instruction, it doesn’t necessarily wait until all previous instructions to execute before reading the counter. Similarly, subsequent instructions may begin executing before the timer is read. This can cause problems if the programmer expects the timestamp to be take at the exact location of the instruction. Making this instruction behave requires some form of synchronization instruction:</p>

<ul>
  <li>If software requires <code class="language-plaintext highlighter-rouge">RDTSC</code> to be executed only after all previous instructions have executed on Intel platforms, it can execute <code class="language-plaintext highlighter-rouge">LFENCE</code> immediately before <code class="language-plaintext highlighter-rouge">RDTSC</code>.</li>
  <li>If software requires <code class="language-plaintext highlighter-rouge">RDTSC</code> to be executed only after all previous instructions have executed on AMD platforms, it can execute <code class="language-plaintext highlighter-rouge">MFENCE</code> immediately before <code class="language-plaintext highlighter-rouge">RDTSC</code>. Technically this is slower than the Intel solution as it waits until all previous loads and stores are globally visible. Executing <code class="language-plaintext highlighter-rouge">LFENCE</code> on AMD hardware doesn’t synchronize as intended.</li>
  <li>If software requires <code class="language-plaintext highlighter-rouge">RDTSC</code> to be executed prior to execution of any subsequent instruction, it can execute <code class="language-plaintext highlighter-rouge">LFENCE</code> immediately after <code class="language-plaintext highlighter-rouge">RDTSC</code>.</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">RDTSCP</code> [Available when <code class="language-plaintext highlighter-rouge">CPUID.80000001h:EDX[27]</code>, is set] is a none speculative version of <code class="language-plaintext highlighter-rouge">RDTSC</code>, equivalent to the first two items above. It waits for all prior instructions to execute before reading the timer and it works the same on AMD and Intel hardware. It doesn’t prevent future instructions from starting to execute, which software can prevent by executing <code class="language-plaintext highlighter-rouge">LFENCE</code> after <code class="language-plaintext highlighter-rouge">RDTSCP</code> (item 3 above). A feature of this newer instruction, unrelated to timers, is the model specific register IA32_TSC_AUX is returned in register ECX, the windows scheduler puts the processor ID in this register, which software can use to determine if your thread is hopping processors (linux does something similar but its entirely dependent on the operating system to set this model specific register).</p>

<p>Going back to QueryPerformanceCounter, you can see all of the above options being used, the code flow is controlled by the QPC flags at <code class="language-plaintext highlighter-rouge">0x7FFE03C6h</code>, the DDK names the various flags as follows:</p>

<p><code class="language-plaintext highlighter-rouge">SHARED_GLOBAL_FLAGS_QPC_BYPASS_ENABLED = 0x01</code> Set if QPC should bypass the syscall and use the timestamp instructions, this will only be set if the timestamp is invariant. This flag first appeared in Window8.1. If this bit is clear QPC just calls <code class="language-plaintext highlighter-rouge">NtQueryPerformanceCounter</code> which is always a syscall, this allows motherboard timers to be used which are only accessible from kernel mode. If the bypass is not enabled then <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> is always a system call with significant cpu overhead, making it somewhat unsuitable for high frequency operations as a single call can take a few microseconds to execute (many thousands of clock cycles).</p>

<p><code class="language-plaintext highlighter-rouge">SHARED_GLOBAL_FLAGS_QPC_BYPASS_USE_HV_PAGE = 0x02</code> If set QPC uses the hypervisor page, this new memory page showed in Windows 10 v1607 and is mapped to all processes much the same way as <code class="language-plaintext highlighter-rouge">kuser_shared</code>. The memory page is used to apply a scale and offset to normalize the frequency to 10MHz (100ns units). This normalization can only occur if the hypervisor page is present so earlier versions of windows will not return a fixed 10Mhz.</p>

<p><code class="language-plaintext highlighter-rouge">SHARED_GLOBAL_FLAGS_QPC_BYPASS_USE_MFENCE = 0x10</code> Use <code class="language-plaintext highlighter-rouge">MFENCE</code> for synchronization, not checked if <code class="language-plaintext highlighter-rouge">RDTSCP</code> is used, only used on AMD processors</p>

<p><code class="language-plaintext highlighter-rouge">SHARED_GLOBAL_FLAGS_QPC_BYPASS_USE_LFENCE = 0x20</code> Use <code class="language-plaintext highlighter-rouge">LFENCE</code> for synchronization, not checked if <code class="language-plaintext highlighter-rouge">RDTDCP</code> is used, only used on Intel processors</p>

<p><code class="language-plaintext highlighter-rouge">SHARED_GLOBAL_FLAGS_QPC_BYPASS_USE_RDTSCP = 0x80</code> If this is set <code class="language-plaintext highlighter-rouge">RDTSCP</code> is available and will be used in place of <code class="language-plaintext highlighter-rouge">RDTSC</code> and syncrhonization.</p>

<p>The syscall is avoided if at all possible and the code path is optimized for using RDTSCP with the hypervisor page to normalize to 10Mhz, this is the code path that has no branches and is the expected code path on typical windows 10 or later machine. Thre are a few other options that can be returned:</p>

<ul>
  <li>
    <p>User mode TSC via <code class="language-plaintext highlighter-rouge">RDTSC or RDTSCP</code> with hypervisor normalization to 10Mhz. CPU cost is 100ish cycles.</p>
  </li>
  <li>
    <p>User mode TSC via <code class="language-plaintext highlighter-rouge">RDTSC or RDTSCP</code> with a shift. On the test machine the shift is set to 10 giving a frequency of 3.613000Mhz (approx 3.7GHz / 1024). CPU cost is about 100 cycles</p>
  </li>
  <li>
    <p>System call.  If this path is being used it will most likely be using the HPET with a frequency of 14.318180MHz, it could also use a PMTimer at 3.579545MHz (exactly 4x slower than the HPET) but its unlikely. CPU cost for the syscall path is thousands of cycles.</p>
  </li>
</ul>

<blockquote>
  <p>Windows 10/11 can be forced to use the HPET counter. From an administrator terminal using <code class="language-plaintext highlighter-rouge">bcdedit /set useplatformclock true</code>. While this could be useful for testin I recommend you don’t leave this boot variable set because it can have some nasty side effects, use <code class="language-plaintext highlighter-rouge">bcdedit /deletevalue useplatformclock</code> to delete the variable and go back to the default. You need to reboot after changing this setting. 
I highly recommend you test with this especially if you are making some high performance media app or game. There are machines out there that use this path and it has caused numerous problems for a handful of commercial games. It also changes the QPC frequency so its no longer the normalized 10Mhz.</p>
</blockquote>

<p>What is this hypervisor page?? Unfortunately, there isn’t much information on it. It first appeared in anniversary update of windows 10 (version 1607) it seems to only be used by <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code>. It’s address isn’t fixed but on all the machines tested it always shows up very close to <code class="language-plaintext highlighter-rouge">kuser_shared</code>, on this test machine it is directly after the kernel page at <code class="language-plaintext highlighter-rouge">0x7ffe1000</code>. You can query the local process address by using native API <code class="language-plaintext highlighter-rouge">NtQuerySystemInformation</code> with query class ID <code class="language-plaintext highlighter-rouge">0xc5</code>.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">extern</span> <span class="s">"C"</span> <span class="n">NTSYSAPI</span> <span class="n">NTSTATUS</span> <span class="n">NTAPI</span>  <span class="nf">NtQuerySystemInformation</span><span class="p">(</span>
    <span class="n">ULONG</span>   <span class="n">SystemInformationClass</span><span class="p">,</span>
    <span class="n">PVOID</span>   <span class="n">SystemInformation</span><span class="p">,</span>
    <span class="n">ULONG</span>   <span class="n">SystemInformationLength</span><span class="p">,</span>
    <span class="n">PULONG</span>  <span class="n">ReturnLength</span>
  <span class="p">);</span>

  <span class="kt">void</span><span class="o">*</span> <span class="nf">GetHypervisorPageAddress</span><span class="p">()</span>
  <span class="p">{</span>
    <span class="kt">void</span><span class="o">*</span> <span class="n">system_info</span><span class="p">;</span>
    <span class="n">ULONG</span> <span class="n">res_size</span><span class="p">;</span>
    <span class="n">NTSTATUS</span> <span class="n">result</span> <span class="o">=</span> <span class="n">NtQuerySystemInformation</span><span class="p">(</span><span class="mh">0xC5</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">system_info</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">system_info</span><span class="p">),</span> <span class="o">&amp;</span><span class="n">res_size</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">((</span><span class="n">result</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">res_size</span> <span class="o">==</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">system_info</span><span class="p">)))</span>
    <span class="p">{</span>
      <span class="k">return</span> <span class="n">system_info</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>Now we can write some code to dump out the known data in the hypervisor page, and compute the TSC frequency as seen by the operating system.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="c1">//known elements of the hypervisor page</span>
  <span class="k">struct</span> <span class="nc">HypervisorPage</span>
  <span class="p">{</span>
    <span class="kt">uint32_t</span>  <span class="n">cookie</span><span class="p">;</span>
    <span class="kt">uint32_t</span>  <span class="n">unused</span><span class="p">;</span> <span class="c1">//maybe cookie is 64bits but it's currently loaded as 32bits</span>
    <span class="kt">uint64_t</span>  <span class="n">rdtsc_scale</span><span class="p">;</span>
    <span class="kt">uint64_t</span>  <span class="n">rdtsc_offset</span><span class="p">;</span>
  <span class="p">};</span>

  <span class="c1">//use the above function</span>
  <span class="n">HypervisorPage</span><span class="o">*</span> <span class="n">hv</span> <span class="o">=</span> <span class="p">(</span><span class="n">HypervisorPage</span><span class="o">*</span><span class="p">)</span><span class="n">GetHypervisorPageAddress</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">hv</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"cookie: %x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">hv</span><span class="o">-&gt;</span><span class="n">cookie</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"rdtsc_cale: %llx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">hv</span><span class="o">-&gt;</span><span class="n">rdtsc_scale</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"rdtsc_offset: %llx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">hv</span><span class="o">-&gt;</span><span class="n">rdtsc_offset</span><span class="p">);</span>

    <span class="c1">//compute the tsc speed as an integer with 32bits of fraction</span>
    <span class="kt">int64_t</span> <span class="n">rem</span><span class="p">;</span>
    <span class="kt">int64_t</span> <span class="n">tsc_int</span> <span class="o">=</span> <span class="n">_div128</span><span class="p">((</span><span class="mi">1ULL</span> <span class="o">&lt;&lt;</span> <span class="mi">32</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">hv</span><span class="o">-&gt;</span><span class="n">rdtsc_scale</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rem</span><span class="p">);</span> 

    <span class="c1">//convert to a double</span>
    <span class="kt">double</span> <span class="n">tsc</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="n">tsc_int</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1ULL</span> <span class="o">&lt;&lt;</span> <span class="mi">32</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"tsc clock speed = %.6f"</span><span class="p">,</span> <span class="n">tsc</span><span class="o">*</span><span class="mf">10.0</span><span class="p">);</span> <span class="c1">//*10 for Mhz</span>

    <span class="c1">//this is hacky but surprisingly accurate (only because rdtsc_scale fits in 53bits)</span>
    <span class="c1">//double f = (double)0xffffffffffffffffULL / (double)hv-&gt;rdtsc_scale;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We can see from the disassembly of <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> that if the hypervisor cookie is zero the syscall is used, on Windows 11 the cookie starts at 0x1 and I assume increments if the hypervisor makes changes to the scale or offset, I’ve never seen this happen but it makes sense the hypervisor could change these values and QueryPerformanceCounter is written to handle it (In windows 10 the cookie used to be a value of ‘hAlt’). On my test machine rdtsc_scale is slighly different on every reboot so its probably being computed at startup, for example on the first boot <code class="language-plaintext highlighter-rouge">0x00b11b8333a4a9e5</code> which in 64bit fixed point is 1/370.035209, on the 2nd boot <code class="language-plaintext highlighter-rouge">0x00b11b77df38e17c</code> or 1/370.0355705, both are very close to the divosr required to get 100ns units from a processor with a base speed of 3.7GHz.</p>

<p>Another time related use for <a href="https://learn.microsoft.com/en-us/windows/win32/api/winternl/nf-winternl-ntquerysysteminformation"><code class="language-plaintext highlighter-rouge">NtQuerySystemInformation</code></a> is to determine if <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> is going to use a syscall or if its going to stay in user mode. You could figure this out yourself the offical method (albiet somewhat undocumented) will be correct in the future. Knowing a syscall is going to be used might change how you use <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code>.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">bool</span> <span class="nf">DoesQPCBypassKernel</span><span class="p">()</span>
<span class="p">{</span>
  <span class="k">struct</span> <span class="nc">SYSTEM_QUERY_PERFORMANCE_COUNTER_INFORMATION</span>
  <span class="p">{</span>
    <span class="n">ULONG</span> <span class="n">Version</span><span class="p">;</span>

    <span class="c1">//0x00000001 = kernelqpc</span>
    <span class="n">ULONG</span> <span class="n">Flags</span><span class="p">;</span>
    <span class="n">ULONG</span> <span class="n">ValidFlags</span><span class="p">;</span>
  <span class="p">};</span>

  <span class="n">SYSTEM_QUERY_PERFORMANCE_COUNTER_INFORMATION</span> <span class="n">qpc_info</span><span class="p">;</span>
  <span class="n">ULONG</span> <span class="n">res_size</span><span class="p">;</span>

  <span class="n">qpc_info</span><span class="p">.</span><span class="n">Version</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">//must set the version on input (only version=1 is defined)</span>
  <span class="n">NTSTATUS</span> <span class="n">result</span> <span class="o">=</span> <span class="n">NtQuerySystemInformation</span><span class="p">(</span><span class="mh">0x7c</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">qpc_info</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">qpc_info</span><span class="p">),</span> <span class="o">&amp;</span><span class="n">res_size</span><span class="p">);</span>

  <span class="k">if</span> <span class="p">((</span><span class="n">result</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">res_size</span> <span class="o">==</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">qpc_info</span><span class="p">)))</span>
  <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">qpc_info</span><span class="p">.</span><span class="n">ValidFlags</span> <span class="o">&amp;</span> <span class="mh">0x1</span><span class="p">)</span>  <span class="c1">//is kernel flag valid</span>
    <span class="p">{</span>
      <span class="k">return</span> <span class="p">(</span><span class="n">qpc_info</span><span class="p">.</span><span class="n">Flags</span> <span class="o">&amp;</span> <span class="mh">0x1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">;</span>  <span class="c1">//if valid it needs to be zero to bypass</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="c1">//this is not actually false, but unknown</span>
  <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Have we come full circle? Why don’t we use <code class="language-plaintext highlighter-rouge">RDTSC</code> for time stamps? If <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> is just a wrapper for <code class="language-plaintext highlighter-rouge">RDTSC/RDTSCP</code> then why not avoid all the overhead and execute the instructions directly? Is Microsoft correct in saying everybody should use QueryPerformanceCounter??? Well, it depends..</p>

<p>If <code class="language-plaintext highlighter-rouge">CPUID.80000007H:EDX[8]</code> indicates invariant timestamp support then there is little harm in making your own ultra low overhead timers using <code class="language-plaintext highlighter-rouge">RDTSC/RDTSCP</code>. <code class="language-plaintext highlighter-rouge">RDTSC</code> is the most optimal and I’ve never seen the lack of synchronization cause problems outside of profiling short code sequences. If you do things yourself you do have to figure out the base clock frequency, something that is given to you if you use <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code>. While I don’t see the timestamp instructions becoming unsable again, there is always a risk of some processor changing the invariant timer in ways software doesn’t expect, nobody expected <code class="language-plaintext highlighter-rouge">RDTSC</code> to cause as much trouble as it did when it was first used 30 years ago.</p>

<p>On a modern machine I don’t see any problem in using <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code>, especially if its bypassing the syscall, its plenty fast enough for anything other than maybe micro-profiling short sequences. <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> is pretty future proof when used properly and the OS handles the edge cases and platform differences. For general time keeping, no matter what the <code class="language-plaintext highlighter-rouge">QueryPerformanceCounter</code> timer source may be, or even if its using a syscall, its insignificant overhead. I am starting to see numerous posts online where the frequency is assumed to be a fixed 10MHz, don’t do this! Today, I would only use <code class="language-plaintext highlighter-rouge">RDTSC</code> for careful micro profiling, or if thousands and thousands of timestamps are needed where just the overhead of the API calls is too much.</p>

<p>If you make your own timers and need the TSC frequency I recommend not using the above code outside of a development environment - it will cause you problems in the future and your app will be the one crashing in 10 years. It would be nice if Windows just had an API to give the TSC frequency but it doesn’t. On Intel processors <code class="language-plaintext highlighter-rouge">CPUID 16h</code> can be used to get the base speed but if you want to compute the TSC frequency you can do a one-time calibration by comparing TSC readings against a known system clock or even QueryPerformanceCounter itself, during development you can check your calibration code against the hypervisor frequency to see if if its reliable. If you use a good reference timer and throw out any outliers this type of calibration can be very accurate, it’s future proof, works on Intel and AMD and it accounts for things like virtualization and overclocking. Never calibrate against <code class="language-plaintext highlighter-rouge">GetTickCount</code>, it’ll never be accurate with the amount of jitter we saw earlier.</p>

<p>Finally, the invariant TSC might appear to have the same counter frequency as the base processor speed but it certainly doesn’t increment at that speed. Typically the invariant TSC runs on a much slower, stable and always running reference clock, say 25MHz, or 50Mhz or 100MHz. The core counter increments at this reference speed adding whatever multiplier is required to match the base speed. On my test machine the amount added is 148 to give the impression of a 3.7GHz counter, from this we can calculate a reference clock of 25MHz. On Intel processors this incremnent rate is available from <code class="language-plaintext highlighter-rouge">CPUID 15h</code>. However, things are not that simple because <code class="language-plaintext highlighter-rouge">RDTSC</code> always returns a value that is monotonically incrementing so won’t return the same value twice if you call it back to back. How this is implemented with respect to the reference clock and what is actually returned is model specific - for example some Intel processors only return even numbers. While its safe to assume the invariant TSC is accurate with wall time over long periods, you probably don’t want to use it to time ultra small sections of code, unless you know exactly how RDTSC is implemented on your particular processor.</p>]]></content><author><name>Rob</name></author><category term="[&quot;blog&quot;, &quot;windows&quot;, &quot;bits&quot;]" /><summary type="html"><![CDATA[Under the hood of windows timestamps, the details and the history]]></summary></entry></feed>